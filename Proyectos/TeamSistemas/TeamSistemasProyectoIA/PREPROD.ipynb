{"cells":[{"cell_type":"markdown","metadata":{"id":"DDUWj6g-MO19"},"source":["**PROYECTO CHATVOZ IA CONVERSACIONAL**\n","\n","\n","**Introducción:**\n","El desarrollo de un chatbot que interactúa no solo mediante texto, sino también con respuestas auditivas, es una de las mejoras más atractivas en la experiencia del usuario. La tecnología Text-to-Speech (TTS) ha avanzado lo suficiente como para proporcionar respuestas de voz naturales y personalizadas. Al combinar la interacción conversacional del chatbot con la capacidad de generar audio, puedes crear una interfaz más accesible e inmersiva para los usuarios, facilitando el acceso a la información de manera más inclusiva y eficiente.\n","\n","En este proyecto, hemos integrado un modelo de TTS para que el chatbot no solo responda con texto, sino que también convierta sus respuestas en audio. Esta característica permite que los usuarios no solo lean, sino también escuchen las respuestas del chatbot, mejorando la experiencia y la accesibilidad.\n","\n","**Objetivos del Proyecto:**\n","Integrar un sistema de Text-to-Speech (TTS): Implementar un mecanismo en el que el chatbot pueda convertir sus respuestas textuales en audio utilizando tecnologías de conversión de texto a voz, como la biblioteca gTTS.\n","\n","Crear una interfaz interactiva usando Gradio: Proporcionar una interfaz de usuario en la que el chatbot pueda recibir preguntas, responder con texto, y ofrecer una reproducción en audio de sus respuestas.\n","\n","Permitir la personalización de la voz: Incluir opciones que permitan a los usuarios ajustar la velocidad de la voz y seleccionar diferentes idiomas para la conversión de texto a voz.\n","\n","Generar respuestas tanto en texto como en audio: Cada vez que el usuario realice una consulta al chatbot, éste responderá con un texto que se podrá leer y, simultáneamente, con un archivo de audio que se puede reproducir directamente en la interfaz.\n","\n","**Gestionar el historial de conversación:** Mantener un registro del historial de conversación entre el usuario y el chatbot, con un formato claro y visual, que permita ver las interacciones anteriores.\n","\n","Facilitar la carga de documentos PDF: Proporcionar la capacidad de cargar y procesar documentos PDF, de los cuales el chatbot puede extraer información para responder preguntas de manera contextual.\n","\n","Este enfoque ofrece una experiencia de interacción enriquecida, con la ventaja añadida de la accesibilidad auditiva, ideal para usuarios que prefieren o necesitan respuestas por voz en lugar de texto.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"uQA2yrD0giDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728040508767,"user_tz":180,"elapsed":89736,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}},"outputId":"e3fff914-12ec-434d-fae5-5e89dccd6e82"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n","Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-5.0.1\n","Collecting langchain\n","  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.8)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.4.0,>=0.3.8 (from langchain)\n","  Downloading langchain_core-0.3.8-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.131-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.8->langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.8->langchain) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.8->langchain) (4.12.2)\n","Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.8->langchain)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Downloading langchain-0.3.2-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.8-py3-none-any.whl (400 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.131-py3-none-any.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.2 langchain-core-0.3.8 langchain-text-splitters-0.3.0 langsmith-0.1.131 orjson-3.10.7 requests-toolbelt-1.0.0 tenacity-8.5.0\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.8)\n","Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n","  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-openai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-openai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-openai) (0.1.131)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-openai) (24.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-openai) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-openai) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-openai) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.2)\n","Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-openai) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-openai) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n","Downloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.51.0-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, tiktoken, openai, langchain-openai\n","Successfully installed jiter-0.5.0 langchain-openai-0.2.1 openai-1.51.0 tiktoken-0.8.0\n","Collecting gtts\n","  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n","Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n","Installing collected packages: gtts\n","Successfully installed gtts-2.5.3\n","Collecting playsound\n","  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: playsound\n","  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=ebbe4ba35873fc383268345ee37ddf7405bfbae9ab7be5e09c36799b45fd2f5c\n","  Stored in directory: /root/.cache/pip/wheels/90/89/ed/2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n","Successfully built playsound\n","Installing collected packages: playsound\n","Successfully installed playsound-1.3.0\n","Collecting python-dotenv\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.1\n","Collecting openai-whisper\n","  Downloading openai-whisper-20240930.tar.gz (800 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n","Collecting triton>=2.0.0 (from openai-whisper)\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n","Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=772b3f5ad1772cf2c45f254a45c05509f175dc6614d5a3aae4cb289b649305ce\n","  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n","Successfully built openai-whisper\n","Installing collected packages: triton, openai-whisper\n","Successfully installed openai-whisper-20240930 triton-3.0.0\n","Collecting pymupdf\n","  Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n","Collecting pdfplumber\n","  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting gradio\n","  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Collecting pdfminer.six==20231228 (from pdfplumber)\n","  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting fastapi<1.0 (from gradio)\n","  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.3.0 (from gradio)\n","  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n","Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n","  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n","Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, pypdfium2, PyPDF2, pymupdf, ffmpy, faiss-cpu, aiofiles, starlette, pdfminer.six, gradio-client, fastapi, pdfplumber, gradio\n","Successfully installed PyPDF2-3.0.1 aiofiles-23.2.1 faiss-cpu-1.8.0.post1 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.1 gradio-client-1.3.0 pdfminer.six-20231228 pdfplumber-0.11.4 pydub-0.25.1 pymupdf-1.24.11 pypdfium2-4.30.0 python-multipart-0.0.12 ruff-0.6.8 semantic-version-2.10.0 starlette-0.38.6 tomlkit-0.12.0 uvicorn-0.31.0 websockets-12.0\n","Collecting langchain-community\n","  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.8)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.2)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.8)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.131)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n","  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n","Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n","Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n","Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.3)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n"]}],"source":["!pip install pypdf\n","!pip install langchain\n","!pip install langchain-openai\n","!pip install gtts\n","!pip install playsound\n","!pip install python-dotenv\n","!pip install openai-whisper\n","!pip install pymupdf pdfplumber PyPDF2 gradio faiss-cpu tiktoken\n","!pip install -U langchain-community\n","!pip install openai\n","!pip install gtts\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QJ1xgAnu7Wr8","executionInfo":{"status":"ok","timestamp":1728040520741,"user_tz":180,"elapsed":9838,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["# Vamos a generar un archivo .py que contenga el código completo que necesitas\n","\n","from gtts import gTTS\n","import gradio as gr\n","import os\n","import tempfile\n","import requests\n","import time\n","import PyPDF2\n","from dotenv import load_dotenv\n"]},{"cell_type":"markdown","source":["**Cargar las variables de entorno desde el\\ archivo .env**"],"metadata":{"id":"DpOFF7qDpxam"}},{"cell_type":"code","source":["load_dotenv()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OozlUsMpH5A7","executionInfo":{"status":"ok","timestamp":1728050118721,"user_tz":180,"elapsed":302,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}},"outputId":"aa0851f0-82eb-498a-d79c-bb187aad8da6"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["dotenv_path = '/content/sample_data/Clave.env'  # Reemplaza con la ruta correcta a tu archivo .env\n","load_dotenv(dotenv_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6qKBJp1NBBv","executionInfo":{"status":"ok","timestamp":1728050123996,"user_tz":180,"elapsed":299,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}},"outputId":"c4a5345a-d788-4446-f5a0-2824771cd9f6"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["api_key = os.getenv(\"OPENAI_API_KEY\")"],"metadata":{"id":"4kwmPuDzNchn","executionInfo":{"status":"ok","timestamp":1728050126759,"user_tz":180,"elapsed":328,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["if not api_key:\n","    raise ValueError(\"La clave de API no está definida. Asegúrate de que está configurada correctamente en el archivo .env.\")\n","\n","# Imprimir para verificar que se ha cargado correctamente (opcional)\n","print(f\"Clave API cargada: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8EGvCG4gLBfs","executionInfo":{"status":"ok","timestamp":1728047645661,"user_tz":180,"elapsed":10,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}},"outputId":"0158dfca-23a1-434b-ba3f-317779a0e4ad"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Clave API cargada: \n"]}]},{"cell_type":"markdown","source":[" **Funcion para cargar la clave API**"],"metadata":{"id":"ilKwOBgwziGj"}},{"cell_type":"code","source":["def cargar_clave_api():\n","    # Obtener la clave de API\n","    api_key = os.getenv(\"OPENAI_API_KEY\")\n","\n","    # Verificar si la clave se ha cargado correctamente\n","    if api_key:\n","        return \"Clave API cargada correctamente\"\n","    else:\n","        return \"Error al cargar la clave API. Verifica el archivo .env.\""],"metadata":{"id":"_iQIqdx_EURM","executionInfo":{"status":"ok","timestamp":1728047645661,"user_tz":180,"elapsed":9,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["\n","# Configuración del endpoint\n","endpoint = \"https://aoai-ine.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview\"\n"],"metadata":{"id":"UcZ0-4Msh7OM","executionInfo":{"status":"ok","timestamp":1728047646068,"user_tz":180,"elapsed":416,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":[" **Función para enviar solicitudes a OpenAI\n","Envía una solicitud al modelo de OpenAI,pasando el prompt (instrucciones) y la entrada del usuario,\n","y maneja posibles errores de red (especialmente errores HTTP 429 que indican demasiadas solicitudes).**"],"metadata":{"id":"MjNIT_GXr9BA"}},{"cell_type":"code","source":["def send_request_to_model(prompt, user_input, api_key, endpoint, retries=5):\n","    headers = {\n","        \"Content-Type\": \"application/json\",\n","        \"api-key\": api_key,\n","    }\n","\n","    payload = {\n","        \"messages\": [\n","            {\"role\": \"system\", \"content\": prompt},  # Aquí se integra el contenido del PDF\n","            {\"role\": \"user\", \"content\": user_input}\n","        ],\n","        \"temperature\": 0.7,\n","        \"top_p\": 0.95,\n","        \"max_tokens\": 800\n","    }\n","\n","    attempt = 0\n","    while attempt < retries:\n","        try:\n","            response = requests.post(endpoint, headers=headers, json=payload)\n","            response.raise_for_status()\n","            response_json = response.json()\n","            return response_json['choices'][0]['message']['content']\n","        except requests.exceptions.HTTPError as e:\n","            if response.status_code == 429:\n","                attempt += 1\n","                wait_time = 5 * (2 ** attempt)\n","                print(f\"HTTP 429: Too Many Requests. Reintentando en {wait_time} segundos...\")\n","                time.sleep(wait_time)\n","            else:\n","                raise SystemExit(f\"Fallo en la solicitud. Error: {e}\")\n","    raise SystemExit(f\"Fallo en la solicitud después de {retries} reintentos.\")"],"metadata":{"id":"biqF-nP3L1UF","executionInfo":{"status":"ok","timestamp":1728047646068,"user_tz":180,"elapsed":15,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":[" **Función para convertir texto a audio usando gTTS\n","Convierte una cadena de texto en un archivo de audio utilizando Google Text-to-Speech (gTTS).**"],"metadata":{"id":"1I6OKDeNs4qb"}},{"cell_type":"code","source":["def convertir_texto_a_audio(texto):\n","    \"\"\"Convierte un texto a audio utilizando gTTS.\"\"\"\n","    tts = gTTS(texto, lang='es')\n","    audio_path = \"output_audio.mp3\"\n","    tts.save(audio_path)\n","    return audio_path"],"metadata":{"id":"d_gIoVRqRXIl","executionInfo":{"status":"ok","timestamp":1728047646068,"user_tz":180,"elapsed":14,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":["**Función para extraer texto desde un PDF usando PyPDF2\n","Extrae texto de un archivo PDF utilizando PyPDF2.\n","Detalles:\n","Extracción por página: Extrae el texto página por página.\n","Control de errores: Verifica si el archivo existe y si es posible extraer texto de las páginas. Si alguna página está vacía, lanza advertencias.**"],"metadata":{"id":"R2ytBe7Vtb0G"}},{"cell_type":"code","execution_count":69,"metadata":{"id":"1RP-U_WDcRnl","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":15,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["def extract_text_from_pdf(pdf_path):\n","    text = \"\"\n","    if not os.path.exists(pdf_path):\n","        raise FileNotFoundError(f\"El archivo PDF no se encuentra en la ruta especificada: {pdf_path}\")\n","\n","    try:\n","        with open(pdf_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page_num, page in enumerate(reader.pages):\n","                page_text = page.extract_text()\n","                if page_text:\n","                    text += page_text + \"\\n\\n\"\n","                else:\n","                    print(f\"Advertencia: No se pudo extraer texto de la página {page_num + 1}.\")\n","    except Exception as e:\n","        raise ValueError(f\"Error al intentar leer el archivo PDF: {e}\")\n","\n","    if not text.strip():\n","        raise ValueError(\"No se pudo extraer texto del PDF o el archivo está vacío.\")\n","\n","    return text\n"]},{"cell_type":"markdown","source":["**Divide el texto en fragmentos (\"chunks\") de tamaño manejable, limitados por el número de caracteres.\n","Palabras: El texto se divide por palabras y se reorganiza en fragmentos más pequeños basados en el límite de tamaño (max_chunk_size).\n","**El propósito de esta función es esencial para reducir la longitud de textos largos. Está bien situada en el código y debería ejecutarse después de extraer el texto de los PDFs**"],"metadata":{"id":"5cvtqhrwuD4x"}},{"cell_type":"code","source":["def chunk_text(text, max_chunk_size=1000):\n","    chunks = []\n","    words = text.split(\" \")\n","    current_chunk = []\n","    for word in words:\n","        if len(\" \".join(current_chunk)) + len(word) + 1 <= max_chunk_size:\n","            current_chunk.append(word)\n","        else:\n","            chunks.append(\" \".join(current_chunk))\n","            current_chunk = [word]\n","    if current_chunk:\n","        chunks.append(\" \".join(current_chunk))\n","    return chunks"],"metadata":{"id":"iZDyUZutL-q8","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":14,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["# este codigo lo usamos para un unico PDF\n","# Cargar y chunkear un único PDF\n","# Este codigo lo dejamos implementado pero comentado para un archivo pdf\n","#def load_single_pdf_and_chunk(pdf_path):\n"," #   text = extract_text_from_pdf(pdf_path)\n","  #  if text:\n","   #     print(\"Texto extraído correctamente del PDF. Aquí hay una muestra:\")\n","    #    print(text[:500])  # Imprimir los primeros 500 caracteres del texto\n","    #else:\n","     #   print(\"No se pudo extraer texto del PDF.\")\n","    #chunks = chunk_text_by_paragraphs(text)\n","    #return chunks"],"metadata":{"id":"YpRXkCQBbl9p","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":14,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":["**Función para cargar y extraer el texto de todos los PDFs en una carpeta\n","Propósito:\n","Carga todos los PDFs de un directorio, extrae el texto y los divide en fragmentos (\"chunks\")**\n","\n","* **Detalles:\n","Extracción masiva: Procesa todos los archivos PDF en un directorio.\n","Integración con extract_text_from_pdf y chunk_text: Combina las funciones anteriores para obtener los fragmentos.#Esta función la usamos para varios pdf***"],"metadata":{"id":"tqoL0vlXvTsz"}},{"cell_type":"code","source":["def load_pdfs_from_directory(directory_path):\n","    all_chunks = []\n","    for file_name in os.listdir(directory_path):\n","        if file_name.endswith(\".pdf\"):  # Solo procesar archivos PDF\n","            pdf_path = os.path.join(directory_path, file_name)\n","            text = extract_text_from_pdf(pdf_path)\n","            if text:\n","                print(f\"Texto extraído correctamente del archivo {file_name}.\")\n","                # Dividimos el texto en chunks manejables\n","                chunks = chunk_text(text, max_chunk_size=1000)\n","                all_chunks.extend(chunks)  # Añadir todos los chunks a la lista\n","            else:\n","                print(f\"No se pudo extraer texto del archivo {file_name}.\")\n","\n","    if not all_chunks:\n","        raise ValueError(\"No se pudo extraer texto de ningún archivo PDF o todos los archivos están vacíos.\")\n","\n","    return all_chunks  # Devolver los chunks en lugar del texto completo"],"metadata":{"id":"j8Cqs60UMEyj","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":14,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":[" **Función para encontrar el chunk más relevante basado en la pregunta del usuario\n","Propósito:\n","Encuentra el fragmento más relevante en función de la cantidad de palabras comunes entre la pregunta del usuario y los fragmentos de texto.\n","Detalles:\n","Búsqueda basada en intersección: Compara las palabras en el fragmento y la pregunta del usuario para calcular el \"overlap\" (superposición)\n","y selecciona el fragmento más relevante.\n","Esta función es esencial para asegurarse de que el modelo reciba el fragmento más relevante antes de responder.**"],"metadata":{"id":"AQbrMPsyyQvn"}},{"cell_type":"code","source":["def find_relevant_chunk(chunks, user_input):\n","    \"\"\"Encuentra el chunk más relevante en función de la pregunta del usuario.\"\"\"\n","    relevant_chunk = \"\"\n","    max_overlap = 0\n","    user_words = set(user_input.lower().split())\n","\n","    # Comparamos la cantidad de palabras comunes entre el chunk y la pregunta\n","    for chunk in chunks:\n","        chunk_words = set(chunk.lower().split())\n","        overlap = len(user_words.intersection(chunk_words))\n","        if overlap > max_overlap:\n","            max_overlap = overlap\n","            relevant_chunk = chunk\n","\n","    return relevant_chunk"],"metadata":{"id":"IJpcOsE-MPgI","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":13,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":[" **Función para manejar la conversación con el chatbot\n","Propósito:\n","Maneja la conversación entre el usuario y el chatbot, buscando el fragmento relevante,\n","enviando la solicitud al modelo y devolviendo la respuesta en texto y audio (opcional).**\n","\n","**Detalles:\n","Combinación de funciones: Integra todas las funciones anteriores para buscar el fragmento relevante,\n","interactuar con el modelo y generar una respuesta.\n","Audio opcional: Si se solicita, también convierte la respuesta en formato de audio.\n","Sugerencia:\n","Es el punto central que conecta todas las demás funcionalidades del chatbot**"],"metadata":{"id":"i0Y7z7vgybgj"}},{"cell_type":"code","source":["def chatbot_conversation(chunks, user_input, api_key, endpoint, respuesta_con_audio=False):\n","    # Encontrar el chunk más relevante\n","    relevant_chunk = find_relevant_chunk(chunks, user_input)\n","\n","    if relevant_chunk:\n","        prompt = f\"Basado en el siguiente texto extraído de archivos PDF:\\n\\n{relevant_chunk}\\n\\nResponde a la pregunta del usuario:\"\n","    else:\n","        prompt = \"No se pudo encontrar información relevante en los archivos PDF.\"\n","\n","    try:\n","        response = send_request_to_model(prompt, user_input, api_key, endpoint)\n","        audio_file = None\n","        if respuesta_con_audio:\n","            # Convertir la respuesta a audio\n","            audio_file = convertir_texto_a_audio(response)\n","        return response, audio_file\n","    except Exception as e:\n","        print(f\"Error en la conversación con el chatbot: {e}\")\n","        return \"Error en la conversación con el modelo.\", None"],"metadata":{"id":"gEWX4wCyBCko","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":13,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["# Función para formatear el historial del chat en HTML\n","def format_history(chat_history):\n","    formatted_history = \"\"\n","    for entry in chat_history:\n","        if entry[\"role\"] == \"user\":\n","            formatted_history += f\"<div class='user'><i class='fas fa-user-circle'></i> <strong>Usuario:</strong> {entry['content']}</div>\"\n","        else:\n","            formatted_history += f\"<div class='bot'><i class='fas fa-robot'></i> <strong>Bot:</strong> {entry['content']}</div>\"\n","    return formatted_history"],"metadata":{"id":"fLUndjkRUNxE","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":13,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","\n","# Función para obtener la fecha y la hora actual\n","def obtener_fecha_hora():\n","    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"],"metadata":{"id":"QLv9kWcwy2zT","executionInfo":{"status":"ok","timestamp":1728049807843,"user_tz":180,"elapsed":302,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["# Función para formatear el historial del chat en HTML con burbujas de color\n","def format_history(chat_history):\n","    formatted_history = \"\"\n","    for entry in chat_history:\n","        timestamp = obtener_fecha_hora()  # Añadimos la marca de tiempo para cada mensaje\n","        if entry[\"role\"] == \"user\":\n","            formatted_history += f\"\"\"\n","            <div style=\"background-color: #d4e6f1; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n","                <strong>🧑 Usuario:</strong> {entry['content']}\n","                <br><small>{timestamp}</small>\n","            </div>\n","            \"\"\"\n","        else:\n","            formatted_history += f\"\"\"\n","            <div style=\"background-color: #b8e994; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n","                <strong>🤖 Bot:</strong> {entry['content']}\n","                <br><small>{timestamp}</small>\n","            </div>\n","            \"\"\"\n","    return formatted_history"],"metadata":{"id":"eaClzFRDTFmr","executionInfo":{"status":"ok","timestamp":1728047646069,"user_tz":180,"elapsed":12,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":[" **Interfaz del chatbot\n","Propósito:\n","Crea la interfaz gráfica para interactuar con el chatbot usando Gradio.\n","Detalles:\n","Gradio: Genera la interfaz donde el usuario puede hacer preguntas al chatbot, ver el historial de chat y recibir respuestas en texto o audio.\n","Interacción con el chatbot: Llama a las funciones necesarias para procesar las solicitudes del usuario y mostrar las respuestas.\n","Utilizamos Gradio para manejar las interacciones con el usuario.**"],"metadata":{"id":"Vc4JTjPmzOAa"}},{"cell_type":"code","source":["def chatbot_ui():\n","    try:\n","        # Directorio donde se encuentran los archivos PDF\n","        directory_path = \"/content/sample_data/EncuestasECH\"  # Cambia esto a la ruta de tu carpeta de PDFs\n","\n","        # Cargar y chunkear todos los PDFs desde la carpeta especificada\n","        chunks = load_pdfs_from_directory(directory_path)\n","\n","        print(f\"Se han cargado {len(chunks)} chunks de los archivos PDF.\")\n","\n","        chat_history = []  # Inicializamos el historial vacío\n","\n","        with gr.Blocks() as demo:\n","            with gr.Row():\n","                with gr.Column(scale=4):\n","                    gr.Markdown(\"# CHATBOT BASADO EN MÚLTIPLES PDFs\")\n","\n","                    # Checkbox para la respuesta en audio\n","                    respuesta_con_audio = gr.Checkbox(label=\"¿Deseas que el chatbot te responda con audio?\", value=False)\n","\n","                    # Campo de entrada de texto para preguntas al chatbot\n","                    user_input = gr.Textbox(label=\"Pregunta al chatbot\", placeholder=\"Escribe tu pregunta aquí...\")\n","\n","                    # Botón para enviar la pregunta\n","                    send_button = gr.Button(\"Enviar\")\n","\n","                    # Campo para mostrar la respuesta del chatbot\n","                    chat_output = gr.Textbox(label=\"Respuesta del chatbot\", interactive=False)\n","\n","                    # Campo para mostrar el audio de la respuesta\n","                    audio_output = gr.Audio(label=\"Respuesta en Audio\", interactive=False)\n","\n","                with gr.Column(scale=2):\n","                    with gr.Row():\n","                        # Botón para limpiar el historial\n","                        clear_button = gr.Button(\"Limpiar historial\")\n","\n","                    gr.Markdown(\"## Historial del Chat\")\n","\n","                    # Campo para mostrar el historial del chat\n","                    history_output = gr.HTML(value=\"\"\"\n","                        <div style=\"border: 2px solid #ccc; border-radius: 15px; padding: 15px; background-color: #f9f9f9; height: 400px; width: 100%; overflow-y: auto;\" id=\"chat_container\">\n","                        </div>\n","                    \"\"\")\n","\n","            # Función para interactuar con el chatbot\n","            def interact(input_text, con_audio):\n","                nonlocal chat_history, chunks\n","                answer, audio_file = chatbot_conversation(chunks, input_text, api_key, endpoint, con_audio)\n","                timestamp = obtener_fecha_hora()\n","\n","                # Actualizar el historial con la nueva interacción\n","                chat_history.append({\"role\": \"user\", \"content\": input_text})  # Añadir entrada del usuario\n","                chat_history.append({\"role\": \"bot\", \"content\": answer})  # Añadir respuesta del bot\n","\n","                # Formatear el historial del chat\n","                formatted_history = format_history(chat_history)\n","\n","                return answer, formatted_history, audio_file if con_audio else None\n","\n","            # Vincular las funciones a los eventos\n","            send_button.click(interact, inputs=[user_input, respuesta_con_audio], outputs=[chat_output, history_output, audio_output])\n","\n","        demo.launch(share=True, debug=True)\n","\n","    except Exception as e:\n","        print(f\"Error creando la interfaz del chatbot: {e}\")"],"metadata":{"id":"nJQfXw-IzYtj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ejecutar la interfaz\n","if __name__ == \"__main__\":\n","    chatbot_ui()\n"],"metadata":{"id":"B6kXzAEftSAI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ac1abc69-3301-4e09-f9be-5b50197638b8","executionInfo":{"status":"ok","timestamp":1728047685759,"user_tz":180,"elapsed":480,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Error creando la interfaz del chatbot: [Errno 2] No such file or directory: '/content/sample_data/EncuestasECH'\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1SngUdbaXdilso9mBLs1VZlJcCWu1w-e0","timestamp":1727798066929},{"file_id":"1nKJZPP6lKv75MsgLWe7HXQj6Mnd2bO3X","timestamp":1727790908997},{"file_id":"1v_wXjZXcJNpkcncwjL9vSgm639m0K6lc","timestamp":1727708275954},{"file_id":"14OwDnEfQoix0cquxtFR6FN7SaS2CSMeN","timestamp":1727652030832},{"file_id":"1qWDv0X8ksUWLDPNCRQJYgsr4lWI5_c4k","timestamp":1727467024714}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}