{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDUWj6g-MO19"
      },
      "source": [
        "**PROYECTO CHATVOZ IA CONVERSACIONAL**\n",
        "\n",
        "\n",
        "**Introducción:**\n",
        "El desarrollo de un chatbot que interactúa no solo mediante texto, sino también con respuestas auditivas, es una de las mejoras más atractivas en la experiencia del usuario. La tecnología Text-to-Speech (TTS) ha avanzado lo suficiente como para proporcionar respuestas de voz naturales y personalizadas. Al combinar la interacción conversacional del chatbot con la capacidad de generar audio, puedes crear una interfaz más accesible e inmersiva para los usuarios, facilitando el acceso a la información de manera más inclusiva y eficiente.\n",
        "\n",
        "En este proyecto, hemos integrado un modelo de TTS para que el chatbot no solo responda con texto, sino que también convierta sus respuestas en audio. Esta característica permite que los usuarios no solo lean, sino también escuchen las respuestas del chatbot, mejorando la experiencia y la accesibilidad.\n",
        "\n",
        "**Objetivos del Proyecto:**\n",
        "Integrar un sistema de Text-to-Speech (TTS): Implementar un mecanismo en el que el chatbot pueda convertir sus respuestas textuales en audio utilizando tecnologías de conversión de texto a voz, como la biblioteca gTTS.\n",
        "\n",
        "Crear una interfaz interactiva usando Gradio: Proporcionar una interfaz de usuario en la que el chatbot pueda recibir preguntas, responder con texto, y ofrecer una reproducción en audio de sus respuestas.\n",
        "\n",
        "Permitir la personalización de la voz: Incluir opciones que permitan a los usuarios ajustar la velocidad de la voz y seleccionar diferentes idiomas para la conversión de texto a voz.\n",
        "\n",
        "Generar respuestas tanto en texto como en audio: Cada vez que el usuario realice una consulta al chatbot, éste responderá con un texto que se podrá leer y, simultáneamente, con un archivo de audio que se puede reproducir directamente en la interfaz.\n",
        "\n",
        "**Gestionar el historial de conversación:** Mantener un registro del historial de conversación entre el usuario y el chatbot, con un formato claro y visual, que permita ver las interacciones anteriores.\n",
        "\n",
        "Facilitar la carga de documentos PDF: Proporcionar la capacidad de cargar y procesar documentos PDF, de los cuales el chatbot puede extraer información para responder preguntas de manera contextual.\n",
        "\n",
        "Este enfoque ofrece una experiencia de interacción enriquecida, con la ventaja añadida de la accesibilidad auditiva, ideal para usuarios que prefieren o necesitan respuestas por voz en lugar de texto.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA2yrD0giDK",
        "outputId": "b00202f7-8566-40b2-ea89-e399ac668f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/294.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.0.1\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.10 (from langchain)\n",
            "  Downloading langchain_core-0.3.10-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.14.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.10->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.3-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.10-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.135-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.3 langchain-core-0.3.10 langchain-text-splitters-0.3.0 langsmith-0.1.135 orjson-3.10.7 requests-toolbelt-1.0.0 tenacity-8.5.0\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.10)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (0.1.135)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.2)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-openai) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
            "Downloading langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, tiktoken, openai, langchain-openai\n",
            "Successfully installed jiter-0.6.1 langchain-openai-0.2.2 openai-1.51.2 tiktoken-0.8.0\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
            "Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.3\n",
            "Collecting playsound\n",
            "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: playsound\n",
            "  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=aa288d8b7c3f6b4dc254d5d64a3fd12dab38e0d7eeca1c07fe2cc25bb49e1a1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/89/ed/2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n",
            "Successfully built playsound\n",
            "Installing collected packages: playsound\n",
            "Successfully installed playsound-1.3.0\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=a92eb5b76073c47ceb6d1c164e609aa0e7ab7f765ecbcc97c0cc3f66a50ecb79\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 triton-3.1.0\n",
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.0 (from gradio)\n",
            "  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.31.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.39.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.0.2-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.31.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading starlette-0.39.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, pypdfium2, PyPDF2, pymupdf, markupsafe, ffmpy, faiss-cpu, aiofiles, starlette, huggingface-hub, pdfminer.six, gradio-client, fastapi, pdfplumber, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.1\n",
            "    Uninstalling MarkupSafe-3.0.1:\n",
            "      Successfully uninstalled MarkupSafe-3.0.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed PyPDF2-3.0.1 aiofiles-23.2.1 faiss-cpu-1.9.0 fastapi-0.115.2 ffmpy-0.4.0 gradio-5.0.2 gradio-client-1.4.0 huggingface-hub-0.25.2 markupsafe-2.1.5 pdfminer.six-20231228 pdfplumber-0.11.4 pydub-0.25.1 pymupdf-1.24.11 pypdfium2-4.30.0 python-multipart-0.0.12 ruff-0.6.9 semantic-version-2.10.0 starlette-0.39.2 tomlkit-0.12.0 uvicorn-0.31.1 websockets-12.0\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.10)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.135)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.2 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
            "Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.4\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=2d3e37c765d4ed50a327a2c1872fa8052627fb7088d2ddb6bcdc8edd76caab44\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf\n",
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install gtts\n",
        "!pip install playsound\n",
        "!pip install python-dotenv\n",
        "!pip install openai-whisper\n",
        "!pip install pymupdf pdfplumber PyPDF2 gradio faiss-cpu tiktoken\n",
        "!pip install -U langchain-community\n",
        "!pip install openai\n",
        "!pip install SpeechRecognition\n",
        "!pip install fpdf\n",
        "!pip freeze > requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Biblotecas Usadas\n",
        "*   os: Para manejar archivos y rutas.\n",
        "*   gradio: Para construir la interfaz web interactiva.\n",
        "*   requests: Para hacer solicitudes HTTP.\n",
        "*   time: Para gestionar tiempos de espera y reintentos.\n",
        "*   PyPDF2: Para manejar archivos PDF.\n",
        "*   speech_recognition: Para convertir audio a texto.\n",
        "*   gtts: Para convertir texto a audio.\n",
        "*   dotenv: Para cargar variables de entorno\n",
        "*   FPDF: Para generar archivos PDF.\n",
        "*   tempfile: Para crear archivos temporales.**\n",
        "\n"
      ],
      "metadata": {
        "id": "1rXzl_-DipqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ1xgAnu7Wr8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import requests\n",
        "import time\n",
        "import PyPDF2\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime\n",
        "from fpdf import FPDF\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cargar Claves API desde un archivo .env:**"
      ],
      "metadata": {
        "id": "EcAk1JzakZIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6qKBJp1NBBv",
        "outputId": "6496090a-40fb-49ca-ddf8-3d59ea4f6edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clave API cargada correctamente\n"
          ]
        }
      ],
      "source": [
        "dotenv_path = '/content/Clave.env'  # Reemplaza con la ruta correcta a tu archivo .env\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"La clave de API no está definida. Asegúrate de que está configurada correctamente en el archivo .env.\")\n",
        "\n",
        "print(f\"Clave API cargada correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcZ0-4Msh7OM"
      },
      "outputs": [],
      "source": [
        "# Configuración del endpoint\n",
        "endpoint = \"https://aoai-ine.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjNIT_GXr9BA"
      },
      "source": [
        " **Función para enviar solicitudes a OpenAI\n",
        "Envía una solicitud al modelo de OpenAI,pasando el prompt (instrucciones) y la entrada del usuario,\n",
        "y maneja posibles errores de red (especialmente errores HTTP 429 que indican demasiadas solicitudes).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biqF-nP3L1UF"
      },
      "outputs": [],
      "source": [
        "def send_request_to_model(prompt, user_input, api_key, endpoint, retries=5):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": api_key,\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_tokens\": 3000\n",
        "    }\n",
        "\n",
        "    attempt = 0\n",
        "    while attempt < retries:\n",
        "        try:\n",
        "            response = requests.post(endpoint, headers=headers, json=payload, timeout=10)\n",
        "            response.raise_for_status()  # Esto detecta errores HTTP automáticamente\n",
        "            response_json = response.json()\n",
        "            return response_json['choices'][0]['message']['content']\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(\"Error: La solicitud ha superado el tiempo de espera.\")\n",
        "            attempt += 1\n",
        "            time.sleep(2)  # Espera antes de reintentar\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(\"Error: Problema de conexión. Verifique la red.\")\n",
        "            attempt += 1\n",
        "            time.sleep(2)  # Espera antes de reintentar\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            if response.status_code == 429:\n",
        "                attempt += 1\n",
        "                wait_time = 5 * (2 ** attempt)\n",
        "                print(f\"HTTP 429: Too Many Requests. Reintentando en {wait_time} segundos...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"Fallo en la solicitud. Error HTTP: {e.response.status_code}\")\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"Error inesperado: {e}\")\n",
        "            break\n",
        "\n",
        "    raise SystemExit(\"Fallo en la solicitud después de varios intentos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I6OKDeNs4qb"
      },
      "source": [
        " **Función para convertir texto a audio usando gTTS\n",
        "Convierte una cadena de texto en un archivo de audio utilizando Google Text-to-Speech (gTTS).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_gIoVRqRXIl"
      },
      "outputs": [],
      "source": [
        "def convertir_texto_a_audio(texto):\n",
        "    if not texto.strip():\n",
        "        raise ValueError(\"No se puede convertir un texto vacío a audio.\")\n",
        "\n",
        "    try:\n",
        "        tts = gTTS(texto, lang='es')\n",
        "        audio_path = \"output_audio.mp3\"\n",
        "        tts.save(audio_path)\n",
        "        return audio_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error al convertir texto a audio: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convertir audio a texto con speech_recognition**\n"
      ],
      "metadata": {
        "id": "c0baGKmfl_yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convertir_audio_a_texto(audio_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Cargar el archivo de audio\n",
        "    try:\n",
        "        with sr.AudioFile(audio_path) as source:\n",
        "            audio_data = recognizer.record(source)  # Leer el audio del archivo\n",
        "            texto = recognizer.recognize_google(audio_data, language='es-ES')  # Reconocer el audio con Google\n",
        "            return texto\n",
        "    except sr.UnknownValueError:\n",
        "        return \"No se pudo entender el audio.\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Error en la solicitud de reconocimiento de audio: {e}\""
      ],
      "metadata": {
        "id": "vzg1pupYAzMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2ytBe7Vtb0G"
      },
      "source": [
        "**Función para extraer texto desde un PDF usando PyPDF2\n",
        "Extrae texto de un archivo PDF utilizando PyPDF2.\n",
        "Detalles:\n",
        "Extracción por página: Extrae el texto página por página.\n",
        "Control de errores: Verifica si el archivo existe y si es posible extraer texto de las páginas. Si alguna página está vacía, lanza advertencias.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RP-U_WDcRnl"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        raise FileNotFoundError(f\"El archivo PDF no se encuentra en la ruta especificada: {pdf_path}\")\n",
        "\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page_num, page in enumerate(reader.pages):\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\\n\"\n",
        "                else:\n",
        "                    print(f\"Advertencia: No se pudo extraer texto de la página {page_num + 1}.\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error al intentar leer el archivo PDF: {e}\")\n",
        "\n",
        "    if not text.strip():\n",
        "        raise ValueError(\"No se pudo extraer texto del PDF o el archivo está vacío.\")\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cvtqhrwuD4x"
      },
      "source": [
        "**Divide el texto en fragmentos (\"chunks\") de tamaño manejable, limitados por el número de caracteres.\n",
        "Palabras: El texto se divide por palabras y se reorganiza en fragmentos más pequeños basados en el límite de tamaño (max_chunk_size).\n",
        "**El propósito de esta función es esencial para reducir la longitud de textos largos. Está bien situada en el código y debería ejecutarse después de extraer el texto de los PDFs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZDyUZutL-q8"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, max_chunk_size=1000):\n",
        "    chunks = []\n",
        "    words = text.split(\" \")\n",
        "    current_chunk = []\n",
        "    for word in words:\n",
        "        if len(\" \".join(current_chunk)) + len(word) + 1 <= max_chunk_size:\n",
        "            current_chunk.append(word)\n",
        "        else:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpRXkCQBbl9p"
      },
      "outputs": [],
      "source": [
        "# este codigo lo usamos para un unico PDF\n",
        "# Cargar y chunkear un único PDF\n",
        "# Este codigo lo dejamos implementado pero comentado para un archivo pdf\n",
        "#def load_single_pdf_and_chunk(pdf_path):\n",
        " #   text = extract_text_from_pdf(pdf_path)\n",
        "  #  if text:\n",
        "   #     print(\"Texto extraído correctamente del PDF. Aquí hay una muestra:\")\n",
        "    #    print(text[:500])  # Imprimir los primeros 500 caracteres del texto\n",
        "    #else:\n",
        "     #   print(\"No se pudo extraer texto del PDF.\")\n",
        "    #chunks = chunk_text_by_paragraphs(text)\n",
        "    #return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqoL0vlXvTsz"
      },
      "source": [
        "**Función para cargar y extraer el texto de todos los PDFs en una carpeta\n",
        "Propósito:\n",
        "Carga todos los PDFs de un directorio, extrae el texto y los divide en fragmentos (\"chunks\")**\n",
        "\n",
        "* **Detalles:\n",
        "Extracción masiva: Procesa todos los archivos PDF en un directorio.\n",
        "Integración con extract_text_from_pdf y chunk_text: Combina las funciones anteriores para obtener los fragmentos.#Esta función la usamos para varios pdf***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Cqs60UMEyj"
      },
      "outputs": [],
      "source": [
        "def load_pdfs_from_directory(directory_path):\n",
        "    all_chunks = []\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        if file_name.endswith(\".pdf\"):\n",
        "            try:\n",
        "                pdf_path = os.path.join(directory_path, file_name)\n",
        "                text = extract_text_from_pdf(pdf_path)\n",
        "                if text:\n",
        "                    print(f\"Texto extraído correctamente del archivo {file_name}.\")\n",
        "                    chunks = chunk_text(text, max_chunk_size=1000)\n",
        "                    all_chunks.extend(chunks)\n",
        "                else:\n",
        "                    print(f\"No se pudo extraer texto del archivo {file_name}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error al procesar {file_name}: {e}\")\n",
        "\n",
        "    if not all_chunks:\n",
        "        raise ValueError(\"No se pudo extraer texto de ningún archivo PDF o todos los archivos están vacíos.\")\n",
        "\n",
        "    return all_chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQbrMPsyyQvn"
      },
      "source": [
        " **Función para encontrar el chunk más relevante basado en la pregunta del usuario\n",
        "Propósito:\n",
        "Encuentra el fragmento más relevante en función de la cantidad de palabras comunes entre la pregunta del usuario y los fragmentos de texto.\n",
        "Detalles:\n",
        "Búsqueda basada en intersección: Compara las palabras en el fragmento y la pregunta del usuario para calcular el \"overlap\" (superposición)\n",
        "y selecciona el fragmento más relevante.\n",
        "Esta función es esencial para asegurarse de que el modelo reciba el fragmento más relevante antes de responder.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJpcOsE-MPgI"
      },
      "outputs": [],
      "source": [
        "def find_relevant_chunk(chunks, user_input):\n",
        "    \"\"\"Encuentra el chunk más relevante en función de la pregunta del usuario.\"\"\"\n",
        "    relevant_chunk = \"\"\n",
        "    max_overlap = 0\n",
        "    user_words = set(user_input.lower().split())\n",
        "\n",
        "    # Comparamos la cantidad de palabras comunes entre el chunk y la pregunta\n",
        "    for chunk in chunks:\n",
        "        chunk_words = set(chunk.lower().split())\n",
        "        overlap = len(user_words.intersection(chunk_words))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            relevant_chunk = chunk\n",
        "\n",
        "    return relevant_chunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Y7z7vgybgj"
      },
      "source": [
        " **Función para manejar la conversación con el chatbot\n",
        "Propósito:\n",
        "Maneja la conversación entre el usuario y el chatbot, buscando el fragmento relevante,\n",
        "enviando la solicitud al modelo y devolviendo la respuesta en texto y audio (opcional).**\n",
        "\n",
        "**Detalles:\n",
        "Combinación de funciones: Integra todas las funciones anteriores para buscar el fragmento relevante,\n",
        "interactuar con el modelo y generar una respuesta.\n",
        "Audio opcional: Si se solicita, también convierte la respuesta en formato de audio.\n",
        "Sugerencia:\n",
        "Es el punto central que conecta todas las demás funcionalidades del chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEWX4wCyBCko"
      },
      "outputs": [],
      "source": [
        "# Función para interactuar con el chatbot y enviar la respuesta\n",
        "def chatbot_conversation(chunks, user_input, api_key, endpoint, respuesta_con_audio=False):\n",
        "    relevant_chunk = find_relevant_chunk(chunks, user_input)\n",
        "\n",
        "    if relevant_chunk:\n",
        "        prompt = f\"Basado en el siguiente texto extraído de archivos PDF:\\n\\n{relevant_chunk}\\n\\nResponde a la pregunta del usuario:\"\n",
        "    else:\n",
        "        prompt = \"No se pudo encontrar información relevante en los archivos PDF.\"\n",
        "\n",
        "    try:\n",
        "        response = send_request_to_model(prompt, user_input, api_key, endpoint)\n",
        "        audio_file = None\n",
        "        if respuesta_con_audio:\n",
        "            audio_file = convertir_texto_a_audio(response)\n",
        "        return response, audio_file\n",
        "    except Exception as e:\n",
        "        return \"Error en la conversación con el modelo.\", None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Funcion para generar un resumen en PDF**"
      ],
      "metadata": {
        "id": "LfBgCuogn_Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_resumen(texto_pdf, api_key, endpoint):\n",
        "    prompt = f\"Resume el siguiente texto: {texto_pdf}\"\n",
        "    return send_request_to_model(prompt, \"\", api_key, endpoint)"
      ],
      "metadata": {
        "id": "uy7kBlq4tnDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para generar el resumen con un indicador de progreso\n",
        "def procesar_pdf_con_progreso(pdf_path, api_key, endpoint):\n",
        "    progress = gr.Progress()\n",
        "\n",
        "    with progress.tqdm(total=100) as pbar:\n",
        "        # Paso 1: Extraer texto del PDF\n",
        "        texto_pdf = extract_text_from_pdf(pdf_path)\n",
        "        pbar.update(50)  # Actualiza el progreso a la mitad\n",
        "\n",
        "        # Paso 2: Generar resumen del PDF\n",
        "        resumen = generar_resumen(texto_pdf, api_key, endpoint)\n",
        "        pbar.update(50)  # Completa el progreso\n",
        "\n",
        "    return resumen"
      ],
      "metadata": {
        "id": "kM4T66yJyLhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para exportar resumen a PDF\n",
        "def exportar_resumen_pdf(resumen):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(200, 10, resumen)\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n",
        "        pdf.output(temp_file.name)\n",
        "        return temp_file.name"
      ],
      "metadata": {
        "id": "0_CQ6WwqyPq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para manejar la carga y chunking del PDF\n",
        "def cargar_pdf_y_generar_resumen(pdf_path, api_key, endpoint):\n",
        "    # Extraer texto del PDF\n",
        "    texto_pdf = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Generar el resumen del PDF\n",
        "    resumen = generar_resumen(texto_pdf, api_key, endpoint)\n",
        "\n",
        "    return resumen"
      ],
      "metadata": {
        "id": "ew64lwPft-KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLUndjkRUNxE"
      },
      "outputs": [],
      "source": [
        "# Función para formatear el historial del chat en HTML\n",
        "def format_history(chat_history):\n",
        "    formatted_history = \"\"\n",
        "    for entry in chat_history:\n",
        "        timestamp = obtener_fecha_hora()\n",
        "        if entry[\"role\"] == \"user\":\n",
        "            formatted_history += f\"\"\"\n",
        "            <div style=\"background-color: #d4e6f1; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n",
        "                <strong>🧑 Usuario:</strong> {entry['content']}\n",
        "                <br><small>{timestamp}</small>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            formatted_history += f\"\"\"\n",
        "            <div style=\"background-color: #b8e994; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n",
        "                <strong>🤖 Bot:</strong> {entry['content']}\n",
        "                <br><small>{timestamp}</small>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "    return formatted_history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nueva función para limpiar el historial\n",
        "def limpiar_historial(chat_history):\n",
        "    chat_history.clear()\n",
        "    return format_history(chat_history)"
      ],
      "metadata": {
        "id": "l7jKHkFPBPYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLv9kWcwy2zT"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Función para obtener la fecha y la hora actual\n",
        "def obtener_fecha_hora():\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaClzFRDTFmr"
      },
      "outputs": [],
      "source": [
        "# Función para formatear el historial del chat en HTML con burbujas de color\n",
        "def format_history(chat_history):\n",
        "    formatted_history = \"\"\n",
        "    for entry in chat_history:\n",
        "        timestamp = obtener_fecha_hora()  # Añadimos la marca de tiempo para cada mensaje\n",
        "        if entry[\"role\"] == \"user\":\n",
        "            formatted_history += f\"\"\"\n",
        "            <div style=\"background-color: #d4e6f1; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n",
        "                <strong>🧑 Usuario:</strong> {entry['content']}\n",
        "                <br><small>{timestamp}</small>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            formatted_history += f\"\"\"\n",
        "            <div style=\"background-color: #b8e994; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n",
        "                <strong>🤖 Bot:</strong> {entry['content']}\n",
        "                <br><small>{timestamp}</small>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "    return formatted_history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para generar el resumen con un indicador de progreso sin tqdm\n",
        "def procesar_pdf_con_progreso(pdf_path, api_key, endpoint):\n",
        "    progress = gr.Progress()\n",
        "\n",
        "    # Paso 1: Extraer texto del PDF\n",
        "    texto_pdf = extract_text_from_pdf(pdf_path)\n",
        "    progress(50)  # Actualiza el progreso al 50%\n",
        "\n",
        "    # Paso 2: Generar resumen del PDF\n",
        "    resumen = generar_resumen(texto_pdf, api_key, endpoint)\n",
        "    progress(100)  # Completa el progreso al 100%\n",
        "\n",
        "    return resumen"
      ],
      "metadata": {
        "id": "6uIIhhDxzdeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exportar_resumen_pdf(resumen):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(200, 10, resumen)\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n",
        "        pdf.output(temp_file.name)\n",
        "        return temp_file.name"
      ],
      "metadata": {
        "id": "Guenz0Qd059d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para generar el resumen con un indicador de progreso\n",
        "def procesar_pdf_con_progreso(pdf_path, api_key, endpoint):\n",
        "    progress = gr.Progress()\n",
        "\n",
        "    # Paso 1: Extraer texto del PDF\n",
        "    texto_pdf = extract_text_from_pdf(pdf_path)\n",
        "    progress(50)  # Actualiza el progreso al 50%\n",
        "\n",
        "    # Paso 2: Generar resumen del PDF\n",
        "    resumen = generar_resumen(texto_pdf, api_key, endpoint)\n",
        "    progress(100)  # Completa el progreso al 100%\n",
        "\n",
        "    return resumen"
      ],
      "metadata": {
        "id": "au8jvgCV1o07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_historial(chat_history):\n",
        "    chat_history.clear()  # Limpiamos el historial\n",
        "    return format_history(chat_history)  # Devolvemos el historial vacío"
      ],
      "metadata": {
        "id": "RutunTfx_K8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc4JTjPmzOAa"
      },
      "source": [
        " **Interfaz del chatbot\n",
        "Propósito:\n",
        "Crea la interfaz gráfica para interactuar con el chatbot usando Gradio.\n",
        "Detalles:\n",
        "Gradio: Genera la interfaz donde el usuario puede hacer preguntas al chatbot, ver el historial de chat y recibir respuestas en texto o audio.\n",
        "Interacción con el chatbot: Llama a las funciones necesarias para procesar las solicitudes del usuario y mostrar las respuestas.\n",
        "Utilizamos Gradio para manejar las interacciones con el usuario.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJQfXw-IzYtj"
      },
      "outputs": [],
      "source": [
        "# Función para la interfaz del chatbot\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Función para la interfaz del chatbot y el resumen de PDFs\n",
        "def chatbot_ui():\n",
        "    try:\n",
        "        directory_path = \"/content/sample_data/Untitled Folder/ManualesECH\"  # Ruta de la carpeta de los PDFs\n",
        "        chunks = load_pdfs_from_directory(directory_path)  # Carga y chunking de PDFs\n",
        "        chat_history = []\n",
        "\n",
        "        with gr.Blocks() as demo:\n",
        "            with gr.Tab(\"Chatbot\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=4):\n",
        "                        gr.Markdown(\"# CHATBOT BASADO EN MÚLTIPLES PDFs\")\n",
        "\n",
        "                        # Campo de entrada de texto para preguntas al chatbot\n",
        "                        user_input = gr.Textbox(label=\"Pregunta al chatbot\", placeholder=\"Escribe tu pregunta aquí...\")\n",
        "\n",
        "                        # Campo para mostrar la respuesta del chatbot\n",
        "                        chat_output = gr.Textbox(label=\"Respuesta del chatbot\", interactive=False)\n",
        "\n",
        "                        # Checkbox para respuesta en formato de audio\n",
        "                        respuesta_con_audio = gr.Checkbox(label=\"¿Deseas que la respuesta sea en audio?\", value=False)\n",
        "\n",
        "                        # Botón para enviar la pregunta\n",
        "                        send_button = gr.Button(\"Enviar\")\n",
        "\n",
        "                        # Campo para mostrar el audio de la respuesta\n",
        "                        audio_output = gr.Audio(label=\"Respuesta en Audio\", interactive=False)\n",
        "\n",
        "                        # Campo para cargar un archivo de audio\n",
        "                        audio_input = gr.Audio(label=\"Cargar archivo de audio\", type=\"filepath\")\n",
        "\n",
        "                        # Botón para convertir audio a texto\n",
        "                        audio_to_text_button = gr.Button(\"Convertir Audio a Texto\")\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        with gr.Row():\n",
        "                            # Botón para limpiar el historial\n",
        "                            clear_button = gr.Button(\"Limpiar historial\")\n",
        "\n",
        "                        gr.Markdown(\"## Historial del Chat\")\n",
        "\n",
        "                        # Campo para mostrar el historial del chat\n",
        "                        history_output = gr.HTML(value=\"\"\"<div style=\"border: 2px solid #ccc; border-radius: 15px; padding: 15px; background-color: #f9f9f9; height: 400px; width: 100%; overflow-y: auto;\" id=\"chat_container\"></div>\"\"\")\n",
        "\n",
        "            # Nueva pestaña para el resumen de PDFs\n",
        "            with gr.Tab(\"Resumen de PDFs\"):\n",
        "                gr.Markdown(\"## Sección de Resumen de PDFs\")\n",
        "\n",
        "                # Botón para cargar un archivo PDF\n",
        "                pdf_input = gr.File(label=\"Cargar PDF\", type=\"filepath\")\n",
        "\n",
        "                # Botón para generar el resumen del PDF\n",
        "                resumen_output = gr.Textbox(label=\"Resumen del PDF\", interactive=False)\n",
        "                resumen_button = gr.Button(\"Generar Resumen del PDF\")\n",
        "\n",
        "                # Botón para exportar resumen a PDF\n",
        "                export_button = gr.Button(\"Exportar Resumen a PDF\")\n",
        "\n",
        "            # Función para interactuar con el chatbot\n",
        "            def interact(input_text, con_audio):\n",
        "                nonlocal chat_history, chunks\n",
        "                answer, audio_file = chatbot_conversation(chunks, input_text, api_key, endpoint, con_audio)\n",
        "                timestamp = obtener_fecha_hora()\n",
        "\n",
        "                chat_history.append({\"role\": \"user\", \"content\": input_text})\n",
        "                chat_history.append({\"role\": \"bot\", \"content\": answer})\n",
        "\n",
        "                formatted_history = format_history(chat_history)\n",
        "                return answer, formatted_history, audio_file if con_audio else None\n",
        "\n",
        "            # Función para limpiar el historial\n",
        "            def limpiar(input_text=None):\n",
        "                nonlocal chat_history\n",
        "                return \"\", limpiar_historial(chat_history), None\n",
        "\n",
        "            # Función para convertir el audio a texto\n",
        "            def convertir_audio(input_audio_path):\n",
        "                if input_audio_path:\n",
        "                    texto = convertir_audio_a_texto(input_audio_path)\n",
        "                    return texto\n",
        "                else:\n",
        "                    return \"No se ha cargado ningún archivo de audio.\"\n",
        "\n",
        "            # Función para generar el resumen del PDF cargado con progreso\n",
        "            def generar_resumen_pdf_con_progreso(pdf):\n",
        "                if pdf:\n",
        "                    resumen = procesar_pdf_con_progreso(pdf, api_key, endpoint)\n",
        "                    return resumen\n",
        "                else:\n",
        "                    return \"No se ha cargado ningún archivo PDF.\"\n",
        "\n",
        "            # Función para exportar el resumen a un archivo PDF\n",
        "            def exportar_resumen(resumen):\n",
        "                if resumen.strip():\n",
        "                    pdf_file = exportar_resumen_pdf(resumen)\n",
        "                    return pdf_file\n",
        "                else:\n",
        "                    return None\n",
        "\n",
        "            # Vincular las funciones a los eventos en la pestaña del chatbot\n",
        "            send_button.click(interact, inputs=[user_input, respuesta_con_audio], outputs=[chat_output, history_output, audio_output])\n",
        "\n",
        "            # Vincular la función de limpiar historial al botón clear_button\n",
        "            clear_button.click(limpiar, inputs=None, outputs=[chat_output, history_output, audio_output])\n",
        "\n",
        "            # Vincular la conversión de audio a texto al botón correspondiente\n",
        "            audio_to_text_button.click(convertir_audio, inputs=[audio_input], outputs=[chat_output])\n",
        "\n",
        "            # Vincular el botón de resumen del PDF cargado y mostrar progreso en la pestaña de Resumen de PDFs\n",
        "            resumen_button.click(generar_resumen_pdf_con_progreso, inputs=[pdf_input], outputs=[resumen_output])\n",
        "\n",
        "            # Vincular el botón de exportar resumen a PDF\n",
        "            export_button.click(exportar_resumen, inputs=[resumen_output], outputs=[gr.File()])\n",
        "\n",
        "        demo.launch(share=True, debug=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creando la interfaz del chatbot: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "B6kXzAEftSAI",
        "outputId": "258f2848-39ec-4573-d920-ab0112622048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto extraído correctamente del archivo Manual Dispositivo ECH 2021.pdf.\n",
            "Texto extraído correctamente del archivo Manual del Supervisor ECH 2021.pdf.\n",
            "Texto extraído correctamente del archivo Marco de referencia pobreza subjetiva 2021.pdf.\n",
            "Texto extraído correctamente del archivo Residencia habitual.pdf.\n",
            "Texto extraído correctamente del archivo Desempleo.pdf.\n",
            "Texto extraído correctamente del archivo Inactivos.pdf.\n",
            "Texto extraído correctamente del archivo Manual de Critica Codificacion 2021.pdf.\n",
            "Texto extraído correctamente del archivo Ingresos.pdf.\n",
            "Texto extraído correctamente del archivo Puntualización sobre cursos que acreditan EMB y cursos que no acreditan EMB ni EMS.pdf.\n",
            "Texto extraído correctamente del archivo Lugar de trabajo.pdf.\n",
            "Texto extraído correctamente del archivo Manual Operativo ECH 2021.pdf.\n",
            "Texto extraído correctamente del archivo Cómo y dónde se registra canasta de emergencia alimentaria otorgada a través de la aplicación TUAPP.pdf.\n",
            "Texto extraído correctamente del archivo Ocupado.pdf.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9bed3ec0ef1395dbe1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9bed3ec0ef1395dbe1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Ejecutar la interfaz\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot_ui()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}