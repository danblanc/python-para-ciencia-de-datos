{"cells":[{"cell_type":"markdown","metadata":{"id":"DDUWj6g-MO19"},"source":["**PROYECTO CHATVOZ IA CONVERSACIONAL**\n","\n","\n","**Introducción:**\n","El desarrollo de un chatbot que interactúa no solo mediante texto, sino también con respuestas auditivas, es una de las mejoras más atractivas en la experiencia del usuario. La tecnología Text-to-Speech (TTS) ha avanzado lo suficiente como para proporcionar respuestas de voz naturales y personalizadas. Al combinar la interacción conversacional del chatbot con la capacidad de generar audio, puedes crear una interfaz más accesible e inmersiva para los usuarios, facilitando el acceso a la información de manera más inclusiva y eficiente.\n","\n","En este proyecto, hemos integrado un modelo de TTS para que el chatbot no solo responda con texto, sino que también convierta sus respuestas en audio. Esta característica permite que los usuarios no solo lean, sino también escuchen las respuestas del chatbot, mejorando la experiencia y la accesibilidad.\n","\n","**Objetivos del Proyecto:**\n","Integrar un sistema de Text-to-Speech (TTS): Implementar un mecanismo en el que el chatbot pueda convertir sus respuestas textuales en audio utilizando tecnologías de conversión de texto a voz, como la biblioteca gTTS.\n","\n","Crear una interfaz interactiva usando Gradio: Proporcionar una interfaz de usuario en la que el chatbot pueda recibir preguntas, responder con texto, y ofrecer una reproducción en audio de sus respuestas.\n","\n","Permitir la personalización de la voz: Incluir opciones que permitan a los usuarios ajustar la velocidad de la voz y seleccionar diferentes idiomas para la conversión de texto a voz.\n","\n","Generar respuestas tanto en texto como en audio: Cada vez que el usuario realice una consulta al chatbot, éste responderá con un texto que se podrá leer y, simultáneamente, con un archivo de audio que se puede reproducir directamente en la interfaz.\n","\n","**Gestionar el historial de conversación:** Mantener un registro del historial de conversación entre el usuario y el chatbot, con un formato claro y visual, que permita ver las interacciones anteriores.\n","\n","Facilitar la carga de documentos PDF: Proporcionar la capacidad de cargar y procesar documentos PDF, de los cuales el chatbot puede extraer información para responder preguntas de manera contextual.\n","\n","Este enfoque ofrece una experiencia de interacción enriquecida, con la ventaja añadida de la accesibilidad auditiva, ideal para usuarios que prefieren o necesitan respuestas por voz en lugar de texto.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102316,"status":"ok","timestamp":1729186765524,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"},"user_tz":180},"id":"uQA2yrD0giDK","outputId":"5fb62d84-1d6a-41cd-8e3b-aa7f697fb4a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n","Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/294.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-5.0.1\n","Collecting langchain\n","  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.4.0,>=0.3.10 (from langchain)\n","  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.14.0)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.10->langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.12.2)\n","Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Downloading langchain-0.3.3-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.135-py3-none-any.whl (295 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.3 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langsmith-0.1.135 orjson-3.10.7 requests-toolbelt-1.0.0 tenacity-8.5.0\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.12)\n","Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n","  Downloading openai-1.52.0-py3-none-any.whl.metadata (24 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (0.1.135)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (24.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.2)\n","Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n","  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-openai) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-openai) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain-openai) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n","Downloading langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.52.0-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, tiktoken, openai, langchain-openai\n","Successfully installed jiter-0.6.1 langchain-openai-0.2.2 openai-1.52.0 tiktoken-0.8.0\n","Collecting gtts\n","  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n","Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n","Installing collected packages: gtts\n","Successfully installed gtts-2.5.3\n","Collecting playsound\n","  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: playsound\n","  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=b25b066c5d59f917ef3d242a9840a1b6363cc6861064894505ceb0ef6a6eadad\n","  Stored in directory: /root/.cache/pip/wheels/90/89/ed/2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n","Successfully built playsound\n","Installing collected packages: playsound\n","Successfully installed playsound-1.3.0\n","Collecting python-dotenv\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.1\n","Collecting openai-whisper\n","  Downloading openai-whisper-20240930.tar.gz (800 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n","Collecting triton>=2.0.0 (from openai-whisper)\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n","Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=375589704e015414ce692e8f7eb3e4d7fcc9b0e87e8108c69353b07e1d8372d3\n","  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n","Successfully built openai-whisper\n","Installing collected packages: triton, openai-whisper\n","Successfully installed openai-whisper-20240930 triton-3.1.0\n","Collecting pymupdf\n","  Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n","Collecting pdfplumber\n","  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting gradio\n","  Downloading gradio-5.2.1-py3-none-any.whl.metadata (16 kB)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Collecting pdfminer.six==20231228 (from pdfplumber)\n","  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n","Collecting gradio\n","  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n","Collecting gradio-client==1.4.0 (from gradio)\n","  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n","Collecting huggingface-hub>=0.25.1 (from gradio)\n","  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Collecting markupsafe~=2.0 (from gradio)\n","  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.0->gradio) (2024.6.1)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.0->gradio)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n","Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0,>=0.115.2->gradio)\n","  Downloading starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.2)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-5.1.0-py3-none-any.whl (42.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.4.0-py3-none-any.whl (319 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n","Downloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading starlette-0.40.0-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, pypdfium2, PyPDF2, pymupdf, markupsafe, ffmpy, faiss-cpu, aiofiles, starlette, huggingface-hub, pdfminer.six, gradio-client, fastapi, pdfplumber, gradio\n","  Attempting uninstall: markupsafe\n","    Found existing installation: MarkupSafe 3.0.1\n","    Uninstalling MarkupSafe-3.0.1:\n","      Successfully uninstalled MarkupSafe-3.0.1\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.24.7\n","    Uninstalling huggingface-hub-0.24.7:\n","      Successfully uninstalled huggingface-hub-0.24.7\n","Successfully installed PyPDF2-3.0.1 aiofiles-23.2.1 faiss-cpu-1.9.0 fastapi-0.115.2 ffmpy-0.4.0 gradio-5.1.0 gradio-client-1.4.0 huggingface-hub-0.25.2 markupsafe-2.1.5 pdfminer.six-20231228 pdfplumber-0.11.4 pydub-0.25.1 pymupdf-1.24.11 pypdfium2-4.30.0 python-multipart-0.0.12 ruff-0.7.0 semantic-version-2.10.0 starlette-0.40.0 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n","Collecting langchain-community\n","  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.10)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.12)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.135)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n","  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (0.3.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (2.23.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n","Downloading langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n","Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n","Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.2 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n","Collecting SpeechRecognition\n","  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n","Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SpeechRecognition\n","Successfully installed SpeechRecognition-3.10.4\n","Collecting fpdf\n","  Downloading fpdf-1.7.2.tar.gz (39 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fpdf\n","  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=95701bfb5706d69e8124f35261ee0c263164a1a0cad6944104ba6d7a533fa459\n","  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n","Successfully built fpdf\n","Installing collected packages: fpdf\n","Successfully installed fpdf-1.7.2\n"]}],"source":["!pip install pypdf\n","!pip install langchain\n","!pip install langchain-openai\n","!pip install gtts\n","!pip install playsound\n","!pip install python-dotenv\n","!pip install openai-whisper\n","!pip install pymupdf pdfplumber PyPDF2 gradio faiss-cpu tiktoken\n","!pip install -U langchain-community\n","!pip install openai\n","!pip install SpeechRecognition\n","!pip install fpdf\n","!pip freeze > requirements.txt\n"]},{"cell_type":"markdown","source":["\n","# Biblotecas Usadas\n","*   os: Para manejar archivos y rutas.\n","*   gradio: Para construir la interfaz web interactiva.\n","*   requests: Para hacer solicitudes HTTP.\n","*   time: Para gestionar tiempos de espera y reintentos.\n","*   PyPDF2: Para manejar archivos PDF.\n","*   speech_recognition: Para convertir audio a texto.\n","*   gtts: Para convertir texto a audio.\n","*   dotenv: Para cargar variables de entorno\n","*   FPDF: Para generar archivos PDF.\n","*   tempfile: Para crear archivos temporales.**\n","\n"],"metadata":{"id":"1rXzl_-DipqE"}},{"cell_type":"code","execution_count":37,"metadata":{"id":"QJ1xgAnu7Wr8","executionInfo":{"status":"ok","timestamp":1729189752380,"user_tz":180,"elapsed":279,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["import os\n","import gradio as gr\n","import requests\n","import time\n","import PyPDF2\n","import speech_recognition as sr\n","from gtts import gTTS\n","from dotenv import load_dotenv\n","from datetime import datetime\n","from fpdf import FPDF\n","import tempfile\n","from pydub import AudioSegment"]},{"cell_type":"markdown","source":["**Cargar Claves API desde un archivo .env:**"],"metadata":{"id":"EcAk1JzakZIR"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1729186866120,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"},"user_tz":180},"id":"W6qKBJp1NBBv","outputId":"3c212502-d50b-4b8e-e8e3-2fec43496587"},"outputs":[{"output_type":"stream","name":"stdout","text":["Clave API cargada correctamente\n"]}],"source":["dotenv_path = '/content/sample_data/ech/Clave.env'  # Reemplaza con la ruta correcta a tu archivo .env\n","load_dotenv(dotenv_path)\n","\n","api_key = os.getenv(\"OPENAI_API_KEY\")\n","if not api_key:\n","    raise ValueError(\"La clave de API no está definida. Asegúrate de que está configurada correctamente en el archivo .env.\")\n","\n","print(f\"Clave API cargada correctamente\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UcZ0-4Msh7OM","executionInfo":{"status":"ok","timestamp":1729187042539,"user_tz":180,"elapsed":278,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["# Configuración del endpoint\n","endpoint = \"https://aoai-ine.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview\"\n"]},{"cell_type":"markdown","metadata":{"id":"MjNIT_GXr9BA"},"source":[" **Función para enviar solicitudes a OpenAI\n","Envía una solicitud al modelo de OpenAI,pasando el prompt (instrucciones) y la entrada del usuario,\n","y maneja posibles errores de red (especialmente errores HTTP 429 que indican demasiadas solicitudes).**"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"biqF-nP3L1UF","executionInfo":{"status":"ok","timestamp":1729190841211,"user_tz":180,"elapsed":303,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["def send_request_to_model(prompt, user_input, api_key, endpoint, retries=5):\n","    headers = {\n","        \"Content-Type\": \"application/json\",\n","        \"api-key\": api_key,\n","    }\n","\n","    payload = {\n","        \"messages\": [\n","            {\"role\": \"system\", \"content\": prompt},\n","            {\"role\": \"user\", \"content\": user_input}\n","        ],\n","        \"temperature\": 0.7,\n","        \"top_p\": 0.95,\n","        \"max_tokens\": 3000\n","    }\n","\n","    attempt = 0\n","    while attempt < retries:\n","        try:\n","            response = requests.post(endpoint, headers=headers, json=payload, timeout=10)\n","            response.raise_for_status()  # Esto detecta errores HTTP automáticamente\n","            response_json = response.json()\n","            return response_json['choices'][0]['message']['content']\n","        except requests.exceptions.Timeout:\n","            print(\"Error: La solicitud ha superado el tiempo de espera.\")\n","            attempt += 1\n","            time.sleep(2)  # Espera antes de reintentar\n","        except requests.exceptions.ConnectionError:\n","            print(\"Error: Problema de conexión. Verifique la red.\")\n","            attempt += 1\n","            time.sleep(2)  # Espera antes de reintentar\n","        except requests.exceptions.HTTPError as e:\n","            if response.status_code == 429:\n","                attempt += 1\n","                wait_time = 5 * (2 ** attempt)\n","                print(f\"HTTP 429: Too Many Requests. Reintentando en {wait_time} segundos...\")\n","                time.sleep(wait_time)\n","            else:\n","                print(f\"Fallo en la solicitud. Error HTTP: {e.response.status_code}\")\n","                break\n","        except Exception as e:\n","            print(f\"Error inesperado: {e}\")\n","            break\n","\n","    raise SystemExit(\"Fallo en la solicitud después de varios intentos.\")"]},{"cell_type":"markdown","metadata":{"id":"1I6OKDeNs4qb"},"source":[" **Función para convertir texto a audio usando gTTS\n","Convierte una cadena de texto en un archivo de audio utilizando Google Text-to-Speech (gTTS).**"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"d_gIoVRqRXIl","executionInfo":{"status":"ok","timestamp":1729190227905,"user_tz":180,"elapsed":319,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["def convertir_texto_a_audio(texto):\n","    if not texto.strip():\n","        raise ValueError(\"No se puede convertir un texto vacío a audio.\")\n","\n","    try:\n","        tts = gTTS(texto, lang='es')\n","        audio_path = \"output_audio.mp3\"\n","        tts.save(audio_path)\n","        return audio_path\n","    except Exception as e:\n","        print(f\"Error al convertir texto a audio: {e}\")\n","        return None"]},{"cell_type":"markdown","source":["**Convertir audio a texto con speech_recognition**\n"],"metadata":{"id":"c0baGKmfl_yD"}},{"cell_type":"code","source":["# Función para convertir audio a texto\n","def convertir_audio_a_texto(audio_path):\n","    recognizer = sr.Recognizer()\n","\n","    # Primero convertir a WAV si es MP3 u otro formato\n","    if not audio_path.endswith(\".wav\"):\n","        audio_path = convertir_a_wav(audio_path)\n","\n","    try:\n","        with sr.AudioFile(audio_path) as source:\n","            audio_data = recognizer.record(source)\n","            texto = recognizer.recognize_google(audio_data, language='es-ES')\n","            return texto\n","    except sr.UnknownValueError:\n","        return \"No se pudo entender el audio.\"\n","    except sr.RequestError as e:\n","        return f\"Error en la solicitud de reconocimiento de audio: {e}\"\n","    except Exception as e:\n","        return f\"Error al procesar el archivo de audio: {e}\""],"metadata":{"id":"vzg1pupYAzMg","executionInfo":{"status":"ok","timestamp":1729190229036,"user_tz":180,"elapsed":4,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Función para convertir cualquier formato de audio a WAV\n","def convertir_a_wav(audio_path):\n","    try:\n","        audio = AudioSegment.from_file(audio_path)\n","        wav_path = \"temp_audio.wav\"\n","        audio.export(wav_path, format=\"wav\")\n","        return wav_path\n","    except Exception as e:\n","        print(f\"Error al convertir el archivo de audio a WAV: {e}\")\n","        return None"],"metadata":{"id":"fbbIFChNvHk6","executionInfo":{"status":"ok","timestamp":1729189677018,"user_tz":180,"elapsed":279,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R2ytBe7Vtb0G"},"source":["**Función para extraer texto desde un PDF usando PyPDF2\n","Extrae texto de un archivo PDF utilizando PyPDF2.\n","Detalles:\n","Extracción por página: Extrae el texto página por página.\n","Control de errores: Verifica si el archivo existe y si es posible extraer texto de las páginas. Si alguna página está vacía, lanza advertencias.**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1RP-U_WDcRnl","executionInfo":{"status":"ok","timestamp":1729187054085,"user_tz":180,"elapsed":300,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["def extract_text_from_pdf(pdf_path):\n","    text = \"\"\n","    if not os.path.exists(pdf_path):\n","        raise FileNotFoundError(f\"El archivo PDF no se encuentra en la ruta especificada: {pdf_path}\")\n","\n","    try:\n","        with open(pdf_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page_num, page in enumerate(reader.pages):\n","                page_text = page.extract_text()\n","                if page_text:\n","                    text += page_text + \"\\n\\n\"\n","                else:\n","                    print(f\"Advertencia: No se pudo extraer texto de la página {page_num + 1}.\")\n","    except Exception as e:\n","        raise ValueError(f\"Error al intentar leer el archivo PDF: {e}\")\n","\n","    if not text.strip():\n","        raise ValueError(\"No se pudo extraer texto del PDF o el archivo está vacío.\")\n","\n","    return text\n"]},{"cell_type":"markdown","metadata":{"id":"5cvtqhrwuD4x"},"source":["**Divide el texto en fragmentos (\"chunks\") de tamaño manejable, limitados por el número de caracteres.\n","Palabras: El texto se divide por palabras y se reorganiza en fragmentos más pequeños basados en el límite de tamaño (max_chunk_size).\n","**El propósito de esta función es esencial para reducir la longitud de textos largos. Está bien situada en el código y debería ejecutarse después de extraer el texto de los PDFs**"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"iZDyUZutL-q8","executionInfo":{"status":"ok","timestamp":1729187055993,"user_tz":180,"elapsed":288,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["def chunk_text(text, max_chunk_size=1000):\n","    chunks = []\n","    words = text.split(\" \")\n","    current_chunk = []\n","    for word in words:\n","        if len(\" \".join(current_chunk)) + len(word) + 1 <= max_chunk_size:\n","            current_chunk.append(word)\n","        else:\n","            chunks.append(\" \".join(current_chunk))\n","            current_chunk = [word]\n","    if current_chunk:\n","        chunks.append(\" \".join(current_chunk))\n","    return chunks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpRXkCQBbl9p"},"outputs":[],"source":["# este codigo lo usamos para un unico PDF\n","# Cargar y chunkear un único PDF\n","# Este codigo lo dejamos implementado pero comentado para un archivo pdf\n","#def load_single_pdf_and_chunk(pdf_path):\n"," #   text = extract_text_from_pdf(pdf_path)\n","  #  if text:\n","   #     print(\"Texto extraído correctamente del PDF. Aquí hay una muestra:\")\n","    #    print(text[:500])  # Imprimir los primeros 500 caracteres del texto\n","    #else:\n","     #   print(\"No se pudo extraer texto del PDF.\")\n","    #chunks = chunk_text_by_paragraphs(text)\n","    #return chunks"]},{"cell_type":"markdown","metadata":{"id":"tqoL0vlXvTsz"},"source":["**Función para cargar y extraer el texto de todos los PDFs en una carpeta\n","Propósito:\n","Carga todos los PDFs de un directorio, extrae el texto y los divide en fragmentos (\"chunks\")**\n","\n","* **Detalles:\n","Extracción masiva: Procesa todos los archivos PDF en un directorio.\n","Integración con extract_text_from_pdf y chunk_text: Combina las funciones anteriores para obtener los fragmentos.#Esta función la usamos para varios pdf***"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"j8Cqs60UMEyj","executionInfo":{"status":"ok","timestamp":1729187059363,"user_tz":180,"elapsed":274,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["def load_pdfs_from_directory(directory_path):\n","    all_chunks = []\n","    for file_name in os.listdir(directory_path):\n","        if file_name.endswith(\".pdf\"):\n","            try:\n","                pdf_path = os.path.join(directory_path, file_name)\n","                text = extract_text_from_pdf(pdf_path)\n","                if text:\n","                    print(f\"Texto extraído correctamente del archivo {file_name}.\")\n","                    chunks = chunk_text(text, max_chunk_size=1000)\n","                    all_chunks.extend(chunks)\n","                else:\n","                    print(f\"No se pudo extraer texto del archivo {file_name}.\")\n","            except Exception as e:\n","                print(f\"Error al procesar {file_name}: {e}\")\n","\n","    if not all_chunks:\n","        raise ValueError(\"No se pudo extraer texto de ningún archivo PDF o todos los archivos están vacíos.\")\n","\n","    return all_chunks"]},{"cell_type":"markdown","metadata":{"id":"AQbrMPsyyQvn"},"source":[" **Función para encontrar el chunk más relevante basado en la pregunta del usuario\n","Propósito:\n","Encuentra el fragmento más relevante en función de la cantidad de palabras comunes entre la pregunta del usuario y los fragmentos de texto.\n","Detalles:\n","Búsqueda basada en intersección: Compara las palabras en el fragmento y la pregunta del usuario para calcular el \"overlap\" (superposición)\n","y selecciona el fragmento más relevante.\n","Esta función es esencial para asegurarse de que el modelo reciba el fragmento más relevante antes de responder.**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"IJpcOsE-MPgI","executionInfo":{"status":"ok","timestamp":1729187061391,"user_tz":180,"elapsed":319,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["def find_relevant_chunk(chunks, user_input):\n","    \"\"\"Encuentra el chunk más relevante en función de la pregunta del usuario.\"\"\"\n","    relevant_chunk = \"\"\n","    max_overlap = 0\n","    user_words = set(user_input.lower().split())\n","\n","    # Comparamos la cantidad de palabras comunes entre el chunk y la pregunta\n","    for chunk in chunks:\n","        chunk_words = set(chunk.lower().split())\n","        overlap = len(user_words.intersection(chunk_words))\n","        if overlap > max_overlap:\n","            max_overlap = overlap\n","            relevant_chunk = chunk\n","\n","    return relevant_chunk"]},{"cell_type":"markdown","metadata":{"id":"i0Y7z7vgybgj"},"source":[" **Función para manejar la conversación con el chatbot\n","Propósito:\n","Maneja la conversación entre el usuario y el chatbot, buscando el fragmento relevante,\n","enviando la solicitud al modelo y devolviendo la respuesta en texto y audio (opcional).**\n","\n","**Detalles:\n","Combinación de funciones: Integra todas las funciones anteriores para buscar el fragmento relevante,\n","interactuar con el modelo y generar una respuesta.\n","Audio opcional: Si se solicita, también convierte la respuesta en formato de audio.\n","Sugerencia:\n","Es el punto central que conecta todas las demás funcionalidades del chatbot**"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"gEWX4wCyBCko","executionInfo":{"status":"ok","timestamp":1729187063145,"user_tz":180,"elapsed":256,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["# Función para interactuar con el chatbot y enviar la respuesta\n","def chatbot_conversation(chunks, user_input, api_key, endpoint, respuesta_con_audio=False):\n","    relevant_chunk = find_relevant_chunk(chunks, user_input)\n","\n","    if relevant_chunk:\n","        prompt = f\"Basado en el siguiente texto extraído de archivos PDF:\\n\\n{relevant_chunk}\\n\\nResponde a la pregunta del usuario:\"\n","    else:\n","        prompt = \"No se pudo encontrar información relevante en los archivos PDF.\"\n","\n","    try:\n","        response = send_request_to_model(prompt, user_input, api_key, endpoint)\n","        audio_file = None\n","        if respuesta_con_audio:\n","            audio_file = convertir_texto_a_audio(response)\n","        return response, audio_file\n","    except Exception as e:\n","        return \"Error en la conversación con el modelo.\", None\n"]},{"cell_type":"markdown","source":["**Funcion para generar un resumen en PDF**"],"metadata":{"id":"LfBgCuogn_Md"}},{"cell_type":"code","source":["def generar_resumen(texto_pdf, api_key, endpoint):\n","    prompt = f\"Resume el siguiente texto: {texto_pdf}\"\n","    return send_request_to_model(prompt, \"\", api_key, endpoint)"],"metadata":{"id":"uy7kBlq4tnDg","executionInfo":{"status":"ok","timestamp":1729187336673,"user_tz":180,"elapsed":268,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Explicación de la función `procesar_pdf_con_progreso`\n","\n","La función `**procesar_pdf_con_progreso**` se encarga de procesar un archivo PDF para extraer su texto y generar un resumen, mostrando un indicador de progreso durante todo el proceso. A continuación se detallan los pasos que realiza la función:\n","\n","## Argumentos de la función:\n","\n","1. **`pdf_path`**: Es la ruta del archivo PDF que se desea procesar.\n","2. **`api_key`**: Clave de API que probablemente se utiliza para interactuar con un servicio de resumen.\n","3. **`endpoint`**: El endpoint de la API al que se envía la solicitud para generar el resumen.\n","\n","## Indicador de progreso (`**gr.Progress()**`):\n","\n","- La función utiliza `**gr.Progress()**` para crear un indicador visual del progreso. Se basa en la biblioteca **Gradio**, que facilita la creación de interfaces interactivas en Python.\n","- Se define un total del progreso de **100** (representando el 100%).\n","\n","## Proceso:\n","\n","1. **Extracción de texto del PDF**:\n","   - La función llama a `**extract_text_from_pdf(pdf_path)**` para extraer el texto del PDF proporcionado.\n","   - Tras completar la extracción, se actualiza el progreso al **50%** (`**pbar.update(50)**`).\n","\n","2. **Generación del resumen**:\n","   - A continuación, llama a `**generar_resumen(texto_pdf, api_key, endpoint)**`, que genera un resumen del texto extraído utilizando un servicio API.\n","   - Una vez generado el resumen, el progreso se actualiza al **100%** (`**pbar.update(50)**`), indicando que el proceso ha finalizado.\n","\n","3. **Retorno**:\n","   - Finalmente, la función devuelve el **resumen generado**.\n","\n","## Consideraciones:\n","\n","- La función utiliza un flujo de trabajo sencillo con dos pasos claros: **extracción de texto** y **generación del resumen**.\n","- El progreso se divide en dos actualizaciones de **50%** cada una.\n","- No se incluye manejo de errores en esta implementación, por lo que puede ser necesario agregar controles adicionales para asegurar que funcione en escenarios no ideales (como fallos en la API o problemas con el archivo PDF).\n","\n","Este enfoque es útil para dar retroalimentación visual al usuario durante tareas que pueden tomar algún tiempo, como el procesamiento de archivos PDF grandes o solicitudes a servicios externos."],"metadata":{"id":"tSzdbmmMliV4"}},{"cell_type":"code","source":["def procesar_pdf_con_progreso(pdf_path, api_key, endpoint):\n","    progress = gr.Progress()\n","\n","    with progress.tqdm(total=100) as pbar:\n","        # Paso 1: Extraer texto del PDF\n","        texto_pdf = extract_text_from_pdf(pdf_path)\n","        pbar.update(50)  # Actualiza el progreso a la mitad\n","\n","        # Paso 2: Generar resumen del PDF\n","        resumen = generar_resumen(texto_pdf, api_key, endpoint)\n","        pbar.update(50)  # Completa el progreso\n","\n","    return resumen"],"metadata":{"id":"kM4T66yJyLhM","executionInfo":{"status":"ok","timestamp":1729187340682,"user_tz":180,"elapsed":277,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["\n","La función **`exportar_resumen_pdf`** genera un archivo PDF a partir de un texto de resumen y lo guarda temporalmente.\n","\n","### Proceso:\n","\n","1. **Crear el PDF**: Se utiliza la biblioteca **FPDF** para crear un objeto PDF, se agrega una página y se define la fuente y tamaño del texto.\n","2. **Insertar el resumen**: El resumen se añade al PDF usando `**pdf.multi_cell()**`, que ajusta el texto a varias líneas.\n","3. **Guardar el archivo**: Se crea un archivo PDF temporal con `**tempfile.NamedTemporaryFile**` y se guarda el contenido del PDF en ese archivo.\n","4. **Devolver la ruta**: La función retorna la ruta del archivo PDF temporal generado.\n","\n","### Consideraciones:\n","- Se utiliza un archivo temporal para almacenar el PDF, lo que permite un manejo dinámico del archivo.\n","- Ideal para exportar resúmenes a PDF y gestionarlos temporalmente."],"metadata":{"id":"RMesHMSHmfE6"}},{"cell_type":"code","source":["def exportar_resumen_pdf(resumen):\n","    pdf = FPDF()\n","    pdf.add_page()\n","    pdf.set_font(\"Arial\", size=12)\n","    pdf.multi_cell(200, 10, resumen)\n","\n","    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n","        pdf.output(temp_file.name)\n","        return temp_file.name"],"metadata":{"id":"0_CQ6WwqyPq0","executionInfo":{"status":"ok","timestamp":1729187453943,"user_tz":180,"elapsed":309,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["La función **`cargar_pdf_y_generar_resumen`** extrae el texto de un archivo PDF y genera un resumen utilizando una API.\n","\n","### Pasos:\n","\n","1. **Extraer texto**: Usa `extract_text_from_pdf` para obtener el contenido del PDF.\n","2. **Generar resumen**: Llama a `generar_resumen` con el texto, la clave de API y el endpoint.\n","\n","### Resultado:\n","- Devuelve el **resumen** del PDF."],"metadata":{"id":"HDkDIyzMm4rs"}},{"cell_type":"code","source":["# Función para manejar la carga y chunking del PDF\n","def cargar_pdf_y_generar_resumen(pdf_path, api_key, endpoint):\n","    # Extraer texto del PDF\n","    texto_pdf = extract_text_from_pdf(pdf_path)\n","\n","    # Generar el resumen del PDF\n","    resumen = generar_resumen(texto_pdf, api_key, endpoint)\n","\n","    return resumen"],"metadata":{"id":"ew64lwPft-KB","executionInfo":{"status":"ok","timestamp":1729187573424,"user_tz":180,"elapsed":266,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"fLUndjkRUNxE","executionInfo":{"status":"ok","timestamp":1729187596927,"user_tz":180,"elapsed":280,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["# Función para formatear el historial del chat en HTML\n","def format_history(chat_history):\n","    formatted_history = \"\"\n","    for entry in chat_history:\n","        timestamp = obtener_fecha_hora()\n","        if entry[\"role\"] == \"user\":\n","            formatted_history += f\"\"\"\n","            <div style=\"background-color: #d4e6f1; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n","                <strong>🧑 Usuario:</strong> {entry['content']}\n","                <br><small>{timestamp}</small>\n","            </div>\n","            \"\"\"\n","        else:\n","            formatted_history += f\"\"\"\n","            <div style=\"background-color: #b8e994; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n","                <strong>🤖 Bot:</strong> {entry['content']}\n","                <br><small>{timestamp}</small>\n","            </div>\n","            \"\"\"\n","    return formatted_history"]},{"cell_type":"code","source":["# Nueva función para limpiar el historial\n","def limpiar_historial(chat_history):\n","    chat_history.clear()\n","    return format_history(chat_history)"],"metadata":{"id":"l7jKHkFPBPYm","executionInfo":{"status":"ok","timestamp":1729187601193,"user_tz":180,"elapsed":268,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"id":"QLv9kWcwy2zT","executionInfo":{"status":"ok","timestamp":1729187602800,"user_tz":180,"elapsed":293,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["from datetime import datetime\n","\n","# Función para obtener la fecha y la hora actual\n","def obtener_fecha_hora():\n","    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"]},{"cell_type":"markdown","source":["La función **`format_history`** formatea un historial de chat en HTML, mostrando mensajes del usuario y del bot en burbujas de color.\n","\n","### Proceso:\n","\n","1. **Recorrer el historial**: Itera sobre cada entrada del historial de chat, que incluye el contenido y el rol (usuario o bot).\n","2. **Formatear cada mensaje**:\n","   - Los mensajes del **usuario** se muestran en una burbuja azul claro (`#d4e6f1`).\n","   - Los mensajes del **bot** se muestran en una burbuja verde claro (`#b8e994`).\n","3. **Agregar marca de tiempo**: Para cada mensaje, se añade una marca de tiempo obtenida con `obtener_fecha_hora()`.\n","4. **HTML final**: Los mensajes se formatean en HTML con bordes redondeados, color de fondo, y etiquetas para identificar quién los envió.\n","\n","### Resultado:\n","- Devuelve el historial formateado en HTML con burbujas de chat diferenciadas para usuario y bot."],"metadata":{"id":"jnUcFaSsnQTe"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"eaClzFRDTFmr","executionInfo":{"status":"ok","timestamp":1729187610668,"user_tz":180,"elapsed":255,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["# Función para formatear el historial del chat en HTML con burbujas de color\n","def format_history(chat_history):\n","    formatted_history = \"\"\n","    for entry in chat_history:\n","        timestamp = obtener_fecha_hora()  # Añadimos la marca de tiempo para cada mensaje\n","        if entry[\"role\"] == \"user\":\n","            formatted_history += f\"\"\"\n","            <div style=\"background-color: #d4e6f1; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n","                <strong>🧑 Usuario:</strong> {entry['content']}\n","                <br><small>{timestamp}</small>\n","            </div>\n","            \"\"\"\n","        else:\n","            formatted_history += f\"\"\"\n","            <div style=\"background-color: #b8e994; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 10px; width: fit-content;\">\n","                <strong>🤖 Bot:</strong> {entry['content']}\n","                <br><small>{timestamp}</small>\n","            </div>\n","            \"\"\"\n","    return formatted_history"]},{"cell_type":"code","source":["# Función para generar el resumen con un indicador de progreso sin tqdm\n","def procesar_pdf_con_progreso(pdf_path, api_key, endpoint):\n","    progress = gr.Progress()\n","\n","    # Paso 1: Extraer texto del PDF\n","    texto_pdf = extract_text_from_pdf(pdf_path)\n","    progress(50)  # Actualiza el progreso al 50%\n","\n","    # Paso 2: Generar resumen del PDF\n","    resumen = generar_resumen(texto_pdf, api_key, endpoint)\n","    progress(100)  # Completa el progreso al 100%\n","\n","    return resumen"],"metadata":{"id":"6uIIhhDxzdeh","executionInfo":{"status":"ok","timestamp":1729187639946,"user_tz":180,"elapsed":297,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["La función **`exportar_resumen_pdf`** genera un archivo PDF a partir de un resumen proporcionado y lo guarda temporalmente.\n","\n","### Proceso:\n","\n","1. **Crear un PDF**: Se utiliza la biblioteca **FPDF** para crear un objeto PDF.\n","2. **Agregar contenido**: Se añade una página, se establece la fuente (`Arial` de tamaño 12), y se inserta el texto del resumen usando `multi_cell`.\n","3. **Guardar temporalmente**: Se guarda el archivo en un archivo temporal con el sufijo `.pdf`.\n","4. **Retornar la ruta**: Devuelve la ruta del archivo PDF temporal generado.\n","\n","### Resultado:\n","- Un archivo PDF con el resumen guardado temporalmente."],"metadata":{"id":"YfwfDHg0njvD"}},{"cell_type":"code","source":["def exportar_resumen_pdf(resumen):\n","    pdf = FPDF()\n","    pdf.add_page()\n","    pdf.set_font(\"Arial\", size=12)\n","    pdf.multi_cell(200, 10, resumen)\n","\n","    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n","        pdf.output(temp_file.name)\n","        return temp_file.name"],"metadata":{"id":"Guenz0Qd059d","executionInfo":{"status":"ok","timestamp":1729187648841,"user_tz":180,"elapsed":280,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Función para generar el resumen con un indicador de progreso\n","def procesar_pdf_con_progreso(pdf_path, api_key, endpoint):\n","    progress = gr.Progress()\n","\n","    # Paso 1: Extraer texto del PDF\n","    texto_pdf = extract_text_from_pdf(pdf_path)\n","    progress(50)  # Actualiza el progreso al 50%\n","\n","    # Paso 2: Generar resumen del PDF\n","    resumen = generar_resumen(texto_pdf, api_key, endpoint)\n","    progress(100)  # Completa el progreso al 100%\n","\n","    return resumen"],"metadata":{"id":"au8jvgCV1o07","executionInfo":{"status":"ok","timestamp":1729187725762,"user_tz":180,"elapsed":4,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def limpiar_historial(chat_history):\n","    chat_history.clear()  # Limpiamos el historial\n","    return format_history(chat_history)  # Devolvemos el historial vacío"],"metadata":{"id":"RutunTfx_K8A","executionInfo":{"status":"ok","timestamp":1729187728432,"user_tz":180,"elapsed":256,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vc4JTjPmzOAa"},"source":[" **Interfaz del chatbot\n","Propósito:\n","Crea la interfaz gráfica para interactuar con el chatbot usando Gradio.\n","Detalles:\n","Gradio: Genera la interfaz donde el usuario puede hacer preguntas al chatbot, ver el historial de chat y recibir respuestas en texto o audio.\n","Interacción con el chatbot: Llama a las funciones necesarias para procesar las solicitudes del usuario y mostrar las respuestas.\n","Utilizamos Gradio para manejar las interacciones con el usuario.**"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"nJQfXw-IzYtj","executionInfo":{"status":"ok","timestamp":1729190731566,"user_tz":180,"elapsed":308,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[],"source":["# Función para la interfaz del chatbot\n","\n","import gradio as gr\n","\n","# Función para la interfaz del chatbot y el resumen de PDFs\n","def chatbot_ui():\n","    try:\n","        directory_path = \"/content/sample_data/ech\"  # Ruta de la carpeta de los PDFs\n","        chunks = load_pdfs_from_directory(directory_path)  # Carga y chunking de PDFs\n","        chat_history = []\n","\n","        with gr.Blocks() as demo:\n","            with gr.Tab(\"Chatbot\"):\n","                with gr.Row():\n","                    with gr.Column(scale=4):\n","                        gr.Markdown(\"# CHATBOT BASADO EN MÚLTIPLES PDFs\")\n","\n","                        # Campo de entrada de texto para preguntas al chatbot\n","                        user_input = gr.Textbox(label=\"Pregunta al chatbot\", placeholder=\"Escribe tu pregunta aquí...\")\n","\n","                        # Campo para mostrar la respuesta del chatbot\n","                        chat_output = gr.Textbox(label=\"Respuesta del chatbot\", interactive=False)\n","\n","                        # Checkbox para respuesta en formato de audio\n","                        respuesta_con_audio = gr.Checkbox(label=\"¿Deseas que la respuesta sea en audio?\", value=False)\n","\n","                        # Botón para enviar la pregunta\n","                        send_button = gr.Button(\"Enviar\")\n","\n","                        # Campo para mostrar el audio de la respuesta\n","                        audio_output = gr.Audio(label=\"Respuesta en Audio\", interactive=False)\n","\n","                        # Campo para cargar un archivo de audio\n","                        audio_input = gr.Audio(label=\"Cargar archivo de audio\", type=\"filepath\")\n","\n","                        # Botón para convertir audio a texto\n","                        audio_to_text_button = gr.Button(\"Convertir Audio a Texto\")\n","\n","                    with gr.Column(scale=2):\n","                        with gr.Row():\n","                            # Botón para limpiar el historial\n","                            clear_button = gr.Button(\"Limpiar historial\")\n","\n","                        gr.Markdown(\"## Historial del Chat\")\n","\n","                        # Campo para mostrar el historial del chat\n","                        history_output = gr.HTML(value=\"\"\"<div style=\"border: 2px solid #ccc; border-radius: 15px; padding: 15px; background-color: #f9f9f9; height: 400px; width: 100%; overflow-y: auto;\" id=\"chat_container\"></div>\"\"\")\n","\n","            # Nueva pestaña para el resumen de PDFs\n","            with gr.Tab(\"Resumen de PDFs\"):\n","                gr.Markdown(\"## Sección de Resumen de PDFs\")\n","\n","                # Botón para cargar un archivo PDF\n","                pdf_input = gr.File(label=\"Cargar PDF\", type=\"filepath\")\n","\n","                # Botón para generar el resumen del PDF\n","                resumen_output = gr.Textbox(label=\"Resumen del PDF\", interactive=False)\n","                resumen_button = gr.Button(\"Generar Resumen del PDF\")\n","\n","                # Botón para exportar resumen a PDF\n","                export_button = gr.Button(\"Exportar Resumen a PDF\")\n","\n","            # Función para interactuar con el chatbot\n","            def interact(input_text, con_audio):\n","                nonlocal chat_history, chunks\n","                answer, audio_file = chatbot_conversation(chunks, input_text, api_key, endpoint, con_audio)\n","                timestamp = obtener_fecha_hora()\n","\n","                chat_history.append({\"role\": \"user\", \"content\": input_text})\n","                chat_history.append({\"role\": \"bot\", \"content\": answer})\n","\n","                formatted_history = format_history(chat_history)\n","                return answer, formatted_history, audio_file if con_audio else None\n","\n","            # Función para limpiar el historial\n","            def limpiar(input_text=None):\n","                nonlocal chat_history\n","                return \"\", limpiar_historial(chat_history), None\n","\n","            # Función para convertir el audio a texto\n","            def convertir_audio(input_audio_path):\n","                if input_audio_path:\n","                    texto = convertir_audio_a_texto(input_audio_path)\n","                    return texto\n","                else:\n","                    return \"No se ha cargado ningún archivo de audio.\"\n","\n","            # Función para generar el resumen del PDF cargado con progreso\n","            def generar_resumen_pdf_con_progreso(pdf):\n","                if pdf:\n","                    resumen = procesar_pdf_con_progreso(pdf, api_key, endpoint)\n","                    return resumen\n","                else:\n","                    return \"No se ha cargado ningún archivo PDF.\"\n","\n","            # Función para exportar el resumen a un archivo PDF\n","            def exportar_resumen(resumen):\n","                if resumen.strip():\n","                    pdf_file = exportar_resumen_pdf(resumen)\n","                    return pdf_file\n","                else:\n","                    return None\n","\n","            # Vincular las funciones a los eventos en la pestaña del chatbot\n","            send_button.click(interact, inputs=[user_input, respuesta_con_audio], outputs=[chat_output, history_output, audio_output])\n","\n","            # Vincular la función de limpiar historial al botón clear_button\n","            clear_button.click(limpiar, inputs=None, outputs=[chat_output, history_output, audio_output])\n","\n","            # Vincular la conversión de audio a texto al botón correspondiente\n","            audio_to_text_button.click(convertir_audio, inputs=[audio_input], outputs=[chat_output])\n","\n","            # Vincular el botón de resumen del PDF cargado y mostrar progreso en la pestaña de Resumen de PDFs\n","            resumen_button.click(generar_resumen_pdf_con_progreso, inputs=[pdf_input], outputs=[resumen_output])\n","\n","            # Vincular el botón de exportar resumen a PDF\n","            export_button.click(exportar_resumen, inputs=[resumen_output], outputs=[gr.File()])\n","\n","        demo.launch(share=True, debug=True)\n","\n","    except Exception as e:\n","        print(f\"Error creando la interfaz del chatbot: {e}\")\n"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":871},"id":"B6kXzAEftSAI","outputId":"61db3144-4334-409b-ea9d-764aec710a7c","executionInfo":{"status":"ok","timestamp":1729191707975,"user_tz":180,"elapsed":52434,"user":{"displayName":"Rodrigo Perez","userId":"17412932632805697523"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Texto extraído correctamente del archivo Lugar de trabajo.pdf.\n","Texto extraído correctamente del archivo Ingresos.pdf.\n","Texto extraído correctamente del archivo Manual Operativo ECH 2021.pdf.\n","Texto extraído correctamente del archivo Manual del Supervisor ECH 2021.pdf.\n","Texto extraído correctamente del archivo Ocupado.pdf.\n","Texto extraído correctamente del archivo Residencia habitual.pdf.\n","Texto extraído correctamente del archivo Puntualización sobre cursos que acreditan EMB y cursos que no acreditan EMB ni EMS.pdf.\n","Texto extraído correctamente del archivo Manual de Critica Codificacion 2021.pdf.\n","Texto extraído correctamente del archivo Manual Dispositivo ECH 2021.pdf.\n","Texto extraído correctamente del archivo Desempleo.pdf.\n","Texto extraído correctamente del archivo Marco de referencia pobreza subjetiva 2021.pdf.\n","Texto extraído correctamente del archivo Cómo y dónde se registra canasta de emergencia alimentaria otorgada a través de la aplicación TUAPP.pdf.\n","Texto extraído correctamente del archivo Inactivos.pdf.\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://6587da7a8cb0256f16.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://6587da7a8cb0256f16.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7861 <> https://6587da7a8cb0256f16.gradio.live\n"]}],"source":["# Ejecutar la interfaz\n","if __name__ == \"__main__\":\n","    chatbot_ui()\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1FAHBxRBKX7fmrRT_gZy3I5aek2lJcHay","timestamp":1728509363290},{"file_id":"1SngUdbaXdilso9mBLs1VZlJcCWu1w-e0","timestamp":1727798066929},{"file_id":"1nKJZPP6lKv75MsgLWe7HXQj6Mnd2bO3X","timestamp":1727790908997},{"file_id":"1v_wXjZXcJNpkcncwjL9vSgm639m0K6lc","timestamp":1727708275954},{"file_id":"14OwDnEfQoix0cquxtFR6FN7SaS2CSMeN","timestamp":1727652030832},{"file_id":"1qWDv0X8ksUWLDPNCRQJYgsr4lWI5_c4k","timestamp":1727467024714}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}