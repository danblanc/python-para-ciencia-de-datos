{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformación de Datos en Machine Learning con Python**\n",
    "\n",
    "Antes de aplicar algoritmos de Machine Learning, es crucial preparar y transformar los datos para mejorar la calidad y el rendimiento del modelo. La transformación de datos incluye técnicas para convertir datos categóricos a numéricos, manejar valores faltantes, normalizar o estandarizar los datos, entre otras. Estas técnicas aseguran que los modelos de ML reciban datos en un formato que maximice su precisión y eficiencia.\n",
    "\n",
    "En este contenido, usaremos un dataset de **Scikit-Learn** y aplicaremos técnicas clásicas de transformación de datos como:\n",
    "\n",
    "1. **One-Hot Encoding**: Convertir variables categóricas en variables binarias.\n",
    "2. **Manejo de Valores Faltantes**: Rellenar o eliminar valores ausentes.\n",
    "3. **Estandarización y Normalización**: Ajustar las características para que tengan una escala similar.\n",
    "4. **Escalado de Características**: Normalización y estandarización.\n",
    "5. **Transformación Logarítmica**: Transformar características sesgadas.\n",
    "\n",
    "### **Dataset Utilizado: Diabetes de Scikit-Learn**\n",
    "\n",
    "Utilizaremos el dataset de **Diabetes** de **Scikit-Learn**, que es un conjunto de datos conocido para problemas de regresión. Este dataset contiene información sobre pacientes y varias características médicas utilizadas para predecir la progresión de la diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019907 -0.017646  \n",
       "1 -0.039493 -0.068332 -0.092204  \n",
       "2 -0.002592  0.002861 -0.025930  \n",
       "3  0.034309  0.022688 -0.009362  \n",
       "4 -0.002592 -0.031988 -0.046641  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el dataset de diabetes\n",
    "data = load_diabetes()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  # Variables independientes\n",
    "y = pd.Series(data.target, name='Progression')  # Variable dependiente\n",
    "\n",
    "# Mostrar los primeros registros del dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. One-Hot Encoding (Codificación One-Hot)**\n",
    "\n",
    "La codificación One-Hot convierte variables categóricas en variables binarias. Para demostrar esta técnica, usaremos un ejemplo simulado.\n",
    "\n",
    "**Ejemplo: Aplicar One-Hot Encoding a una Variable Categórica Simulada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Category_A</th>\n",
       "      <th>Category_B</th>\n",
       "      <th>Category_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  Category_A  Category_B  Category_C  \n",
       "0 -0.002592  0.019907 -0.017646         1.0         0.0         0.0  \n",
       "1 -0.039493 -0.068332 -0.092204         0.0         0.0         1.0  \n",
       "2 -0.002592  0.002861 -0.025930         1.0         0.0         0.0  \n",
       "3  0.034309  0.022688 -0.009362         0.0         0.0         1.0  \n",
       "4 -0.002592 -0.031988 -0.046641         0.0         1.0         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Crear una variable categórica simulada\n",
    "X['Category'] = np.random.choice(['A', 'B', 'C'], size=len(X))\n",
    "\n",
    "# Aplicar One-Hot Encoding usando OneHotEncoder de sklearn\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "category_encoded = encoder.fit_transform(X[['Category']])\n",
    "\n",
    "# Convertir a DataFrame y concatenar con los datos originales\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=encoder.get_feature_names_out(['Category']))\n",
    "X = pd.concat([X, category_encoded_df], axis=1).drop(columns=['Category'])\n",
    "\n",
    "# Mostrar los datos transformados\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Manejo de Valores Faltantes (Handling Missing Values)**\n",
    "\n",
    "El manejo de valores faltantes es esencial para evitar que los modelos de ML arrojen errores o produzcan resultados sesgados. Los métodos comunes incluyen la imputación de valores (relleno) y la eliminación de filas o columnas con datos faltantes.\n",
    "\n",
    "**Ejemplo: Imputación de Valores Faltantes**\n",
    "\n",
    "Supongamos que algunos valores en el dataset están faltando. Vamos a generar valores faltantes intencionalmente para demostrar cómo manejarlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Category_A</th>\n",
       "      <th>Category_B</th>\n",
       "      <th>Category_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680 -0.001126  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  Category_A  Category_B  Category_C  \n",
       "0 -0.002592  0.019907 -0.017646         1.0         0.0         0.0  \n",
       "1 -0.039493 -0.068332 -0.092204         0.0         0.0         1.0  \n",
       "2 -0.002592  0.002861 -0.025930         1.0         0.0         0.0  \n",
       "3  0.034309  0.022688 -0.009362         0.0         0.0         1.0  \n",
       "4 -0.002592 -0.031988 -0.046641         0.0         1.0         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Introducir valores faltantes intencionalmente\n",
    "X.loc[::10, 'bmi'] = np.nan  # Introducir NaN en cada décima fila de la columna 'bmi'\n",
    "\n",
    "# Crear un imputador que reemplaza los valores faltantes con la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X['bmi'] = imputer.fit_transform(X[['bmi']])\n",
    "\n",
    "# Mostrar los datos transformados\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Estandarización y Normalización (Standardization and Normalization)**\n",
    "\n",
    "**Estandarización** y **normalización** son técnicas para escalar las características de los datos a una escala similar, lo que puede mejorar el rendimiento de muchos algoritmos de ML.\n",
    "\n",
    "- **Estandarización**: Ajusta las características para que tengan una media de 0 y una desviación estándar de 1.\n",
    "- **Normalización**: Escala las características en un rango específico, normalmente de 0 a 1.\n",
    "\n",
    "**Ejemplo: Estandarización de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Category_A</th>\n",
       "      <th>Category_B</th>\n",
       "      <th>Category_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800500</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>4.811607e-18</td>\n",
       "      <td>0.459841</td>\n",
       "      <td>-0.929746</td>\n",
       "      <td>-0.732065</td>\n",
       "      <td>-0.912451</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>0.418531</td>\n",
       "      <td>-0.370989</td>\n",
       "      <td>1.423867</td>\n",
       "      <td>-0.670209</td>\n",
       "      <td>-0.749558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.039567</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-1.117196e+00</td>\n",
       "      <td>-0.553505</td>\n",
       "      <td>-0.177624</td>\n",
       "      <td>-0.402886</td>\n",
       "      <td>1.564414</td>\n",
       "      <td>-0.830301</td>\n",
       "      <td>-1.436589</td>\n",
       "      <td>-1.938479</td>\n",
       "      <td>-0.702313</td>\n",
       "      <td>-0.670209</td>\n",
       "      <td>1.334119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.793307</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>1.011350e+00</td>\n",
       "      <td>-0.119214</td>\n",
       "      <td>-0.958674</td>\n",
       "      <td>-0.718897</td>\n",
       "      <td>-0.680245</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>-0.545154</td>\n",
       "      <td>1.423867</td>\n",
       "      <td>-0.670209</td>\n",
       "      <td>-0.749558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.872441</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-2.322948e-01</td>\n",
       "      <td>-0.770650</td>\n",
       "      <td>0.256292</td>\n",
       "      <td>0.525397</td>\n",
       "      <td>-0.757647</td>\n",
       "      <td>0.721302</td>\n",
       "      <td>0.476983</td>\n",
       "      <td>-0.196823</td>\n",
       "      <td>-0.702313</td>\n",
       "      <td>-0.670209</td>\n",
       "      <td>1.334119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113172</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-7.823684e-01</td>\n",
       "      <td>0.459841</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.327890</td>\n",
       "      <td>0.171178</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>-0.672502</td>\n",
       "      <td>-0.980568</td>\n",
       "      <td>-0.702313</td>\n",
       "      <td>1.492072</td>\n",
       "      <td>-0.749558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex           bmi        bp        s1        s2        s3  \\\n",
       "0  0.800500  1.065488  4.811607e-18  0.459841 -0.929746 -0.732065 -0.912451   \n",
       "1 -0.039567 -0.938537 -1.117196e+00 -0.553505 -0.177624 -0.402886  1.564414   \n",
       "2  1.793307  1.065488  1.011350e+00 -0.119214 -0.958674 -0.718897 -0.680245   \n",
       "3 -1.872441 -0.938537 -2.322948e-01 -0.770650  0.256292  0.525397 -0.757647   \n",
       "4  0.113172 -0.938537 -7.823684e-01  0.459841  0.082726  0.327890  0.171178   \n",
       "\n",
       "         s4        s5        s6  Category_A  Category_B  Category_C  \n",
       "0 -0.054499  0.418531 -0.370989    1.423867   -0.670209   -0.749558  \n",
       "1 -0.830301 -1.436589 -1.938479   -0.702313   -0.670209    1.334119  \n",
       "2 -0.054499  0.060156 -0.545154    1.423867   -0.670209   -0.749558  \n",
       "3  0.721302  0.476983 -0.196823   -0.702313   -0.670209    1.334119  \n",
       "4 -0.054499 -0.672502 -0.980568   -0.702313    1.492072   -0.749558  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear un escalador estándar\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar la estandarización a las características\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir el resultado a DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Mostrar los datos estandarizados\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Escalado de Características (Feature Scaling)**\n",
    "\n",
    "El escalado de características ayuda a alinear diferentes características a la misma escala y es especialmente importante para algoritmos sensibles a la escala, como la regresión logística o los SVM.\n",
    "\n",
    "**Ejemplo: Normalización Min-Max de Datos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Category_A</th>\n",
       "      <th>Category_B</th>\n",
       "      <th>Category_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341789</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.256972</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.562217</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.306773</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.141044</td>\n",
       "      <td>0.222437</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.289216</td>\n",
       "      <td>0.258964</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.496578</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.495098</td>\n",
       "      <td>0.447211</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.423131</td>\n",
       "      <td>0.572923</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206612</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.465686</td>\n",
       "      <td>0.417331</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.362385</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex       bmi        bp        s1        s2        s3        s4  \\\n",
       "0  0.666667  1.0  0.341789  0.549296  0.294118  0.256972  0.207792  0.282087   \n",
       "1  0.483333  0.0  0.148760  0.352113  0.421569  0.306773  0.623377  0.141044   \n",
       "2  0.883333  1.0  0.516529  0.436620  0.289216  0.258964  0.246753  0.282087   \n",
       "3  0.083333  0.0  0.301653  0.309859  0.495098  0.447211  0.233766  0.423131   \n",
       "4  0.516667  0.0  0.206612  0.549296  0.465686  0.417331  0.389610  0.282087   \n",
       "\n",
       "         s5        s6  Category_A  Category_B  Category_C  \n",
       "0  0.562217  0.439394         1.0         0.0         0.0  \n",
       "1  0.222437  0.166667         0.0         0.0         1.0  \n",
       "2  0.496578  0.409091         1.0         0.0         0.0  \n",
       "3  0.572923  0.469697         0.0         0.0         1.0  \n",
       "4  0.362385  0.333333         0.0         1.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Crear un escalador Min-Max\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar la normalización a las características\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir el resultado a DataFrame\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Mostrar los datos normalizados\n",
    "X_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Transformación Logarítmica (Log Transformation)**\n",
    "\n",
    "La transformación logarítmica se utiliza para reducir la asimetría (skewness) de las características numéricas. Es útil cuando los datos tienen una distribución muy sesgada.\n",
    "\n",
    "**Ejemplo: Transformación Logarítmica de una Característica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         s1    s1_log\n",
      "0 -0.044223 -0.045231\n",
      "1 -0.008449 -0.008485\n",
      "2 -0.045599 -0.046672\n",
      "3  0.012191  0.012117\n",
      "4  0.003935  0.003927\n"
     ]
    }
   ],
   "source": [
    "# Aplicar una transformación logarítmica a la columna 's1'\n",
    "X['s1_log'] = np.log1p(X['s1'])  # np.log1p() aplica log(1 + x) para manejar ceros\n",
    "\n",
    "# Mostrar los datos transformados\n",
    "print(X[['s1', 's1_log']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Uso de `Pipeline` de Scikit-Learn para Transformación de Datos**\n",
    "\n",
    "El **`Pipeline`** de **Scikit-Learn** permite encadenar varias transformaciones de datos (como One-Hot Encoding, manejo de valores faltantes, escalado de características) y, finalmente, aplicar un estimador (modelo de ML). El `Pipeline` asegura que todas las transformaciones se apliquen de manera consistente a los datos de entrenamiento y de prueba.\n",
    "\n",
    "### **Ejemplo: Usando `Pipeline` para Encadenar Transformaciones de Datos**\n",
    "\n",
    "Vamos a utilizar el dataset de **Diabetes** de **Scikit-Learn** y aplicar múltiples técnicas de preprocesamiento utilizando `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cargar el dataset de diabetes\n",
    "data = load_diabetes()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  # Variables independientes\n",
    "y = pd.Series(data.target, name='Progression')  # Variable dependiente\n",
    "\n",
    "# Introducir una columna categórica simulada\n",
    "X['Category'] = np.random.choice(['A', 'B', 'C'], size=len(X))\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2912.9207449826313\n",
      "Coefficient of Determination (R^2 Score): 0.4502005825336727\n"
     ]
    }
   ],
   "source": [
    "# Definir el preprocesamiento para características numéricas\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Manejo de valores faltantes\n",
    "    ('scaler', StandardScaler())  # Estandarización\n",
    "])\n",
    "\n",
    "# Definir el preprocesamiento para características categóricas\n",
    "categorical_features = ['Category']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot Encoding\n",
    "])\n",
    "\n",
    "# Crear un transformador de columnas (ColumnTransformer) que aplica las transformaciones por tipo de dato\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Crear un Pipeline que aplica el preprocesador seguido de un modelo de regresión lineal\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Entrenar el Pipeline en el conjunto de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Coefficient of Determination (R^2 Score): {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explicación del Código:**\n",
    "\n",
    "1. **División del Dataset**: Dividimos los datos en conjuntos de entrenamiento y prueba utilizando `train_test_split`.\n",
    "\n",
    "2. **Transformador de Características Numéricas**: Definimos un `Pipeline` llamado `numeric_transformer` que maneja los valores faltantes utilizando la media y estandariza las características numéricas.\n",
    "\n",
    "3. **Transformador de Características Categóricas**: Definimos un `Pipeline` llamado `categorical_transformer` que aplica **One-Hot Encoding** a las características categóricas.\n",
    "\n",
    "4. **ColumnTransformer**: Usamos `ColumnTransformer` para aplicar diferentes transformaciones a las características numéricas y categóricas. Esto nos permite transformar tanto datos numéricos como categóricos en un solo paso.\n",
    "\n",
    "5. **Pipeline Completo**: Creamos un `Pipeline` completo que aplica las transformaciones de preprocesamiento (definidas por `preprocessor`) y luego entrena un modelo de regresión lineal (`LinearRegression`).\n",
    "\n",
    "6. **Entrenamiento y Predicción**: Entrenamos el `Pipeline` con los datos de entrenamiento y luego realizamos predicciones en los datos de prueba.\n",
    "\n",
    "7. **Evaluación del Modelo**: Evaluamos el rendimiento del modelo utilizando el error cuadrático medio (MSE) y el coeficiente de determinación (R²).\n",
    "\n",
    "### **Beneficios de Usar `Pipeline` de Scikit-Learn:**\n",
    "\n",
    "- **Simplicidad y Limpieza del Código**: Permite aplicar varias transformaciones y estimadores en una cadena limpia y clara.\n",
    "- **Consistencia**: Asegura que todas las transformaciones se aplican de la misma manera a los datos de entrenamiento y de prueba.\n",
    "- **Repetibilidad**: Facilita la replicación del flujo de trabajo para nuevos datos.\n",
    "- **Facilidad de Ajuste de Hiperparámetros**: Facilita el uso de herramientas de búsqueda de hiperparámetros como `GridSearchCV`.\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "El uso de `Pipeline` en Scikit-Learn es fundamental para construir flujos de trabajo de Machine Learning eficientes y reproducibles. Encadenar transformaciones de datos y modelos en un solo objeto asegura que todas las transformaciones se apliquen de manera consistente, mejorando así la calidad del modelo y simplificando el código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso-ine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
